{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from matplotlib import pyplot\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the MNIST datasets - 60000 images for training and 10000 images for testing\n",
    "(imageTrain, labelTrain), (imageTest, labelTest) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# Splitting the training set into 2: 55000 images for training and 5000 images for validation\n",
    "imageTest = imageTest[:]\n",
    "labelTest = labelTest[:]\n",
    "\n",
    "imageValid = imageTrain[55000:]\n",
    "labelValid = labelTrain[55000:]\n",
    "\n",
    "imageTrain = imageTrain[:55000]\n",
    "labelTrain = labelTrain[:55000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGzCAYAAABpdMNsAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8o6BhiAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAgRUlEQVR4nO3de3BU9fnH8U/CZbmYLMaYm9wCKFi5tILE/EQukhKCIgh1xKIDjAMDBhSo2lIV0DqTSmeU6gDWqSVFBS9TuegINYIJagEHhDJUpYSJXAoJlZnshktCIN/fH4xbV8LlhN08SXi/Zr4z7Nnz7Hk4HPLJ2XP2uzHOOScAAOpZrHUDAIArEwEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQRcpvnz5ysmJqZOtfn5+YqJidG3334b2aaARoAAAn7g+0D4frRq1UppaWnKzs7WSy+9pIqKiqj3sHjxYuXn51/y+rNmzdLNN9+shIQEtWnTRjfeeKPmz5+vY8eORa9JIAJimAsO+J/8/HxNmjRJzz77rNLT01VdXa3S0lIVFhaqoKBAHTt21Jo1a9S7d+9QzenTp3X69Gm1atXK8/bOnDmj6upq+Xy+0FlUz549lZiYqMLCwkt6jQEDBqhv377q1q2bWrVqpe3bt+svf/mL+vXrp40bNyo2lt8z0TA1t24AaIhycnLUr1+/0OM5c+Zow4YNuuuuu3T33Xfr66+/VuvWrSVJzZs3V/Pmdfuv1KxZMzVr1uyyev3ss8/OWda1a1c99thj+uKLL3Trrbde1usD0cKvRsAluuOOO/T0009r3759euONN0LLa7sGdPLkST3yyCNKTExUXFyc7r77bv3nP/9RTEyM5s+fH1rvx9eAOnfurH/9618qKioKvQ04ePBgz7127txZklReXu65FqgvBBDgwYMPPihJ+uijjy643sSJE/Xyyy9rxIgRev7559W6dWvdeeedF339hQsXqn379urRo4def/11vf7663ryyScvWnf69Gl99913OnTokD766CM99dRTiouLU//+/S/tLwYY4C04wIP27dvL7/dr7969513nyy+/1DvvvKOZM2fqxRdflCQ9/PDDmjRpkv75z39e8PVHjx6tp556SomJiXrggQcuua+tW7cqMzMz9Lh79+5as2aNEhISLvk1gPrGGRDg0VVXXXXBu+HWrVsn6Wzo/NCMGTOi1tNPfvITFRQUaNWqVXriiSfUtm1b7oJDg8cZEODRsWPHlJSUdN7n9+3bp9jYWKWnp4ct79atW9R6io+PV1ZWliRp1KhRWr58uUaNGqUvv/xSffr0idp2gcvBGRDgwcGDBxUIBKIaJpEwZswYSdJbb71l3AlwfgQQ4MHrr78uScrOzj7vOp06dVJNTY1KSkrClhcXF1/SNuo6q8IPVVVVqaamRoFA4LJfC4gWAgi4RBs2bNDvfvc7paena/z48edd7/twWrx4cdjyl19++ZK207Zt20u+fbq8vFzV1dXnLP/zn/8sSWGfZQIaGq4BAbVYu3atvvnmG50+fVplZWXasGGDCgoK1KlTJ61Zs+aCsx707dtXY8eO1cKFC3X06FHdeuutKioq0r///W9JFz/D6du3r5YsWaLnnntO3bp1U1JSku64445a1y0sLNQjjzyiX/ziF7r++ut16tQpffrpp3rvvffUr18/T3fSAfWNAAJqMXfuXElSy5YtlZCQoF69emnhwoWaNGmS4uLiLlq/bNkypaSkaMWKFVq5cqWysrL09ttvq3v37hedsmfu3Lnat2+fFixYoIqKCg0aNOi8AdSrVy8NGTJEq1ev1uHDh+WcU9euXTV37lw9/vjjatmypfe/PFBPmAsOqCc7duzQz372M73xxhsXfAsPuFJwDQiIgpMnT56zbOHChYqNjdXAgQMNOgIaHt6CA6JgwYIF2rZtm4YMGaLmzZtr7dq1Wrt2raZMmaIOHTpYtwc0CLwFB0RBQUGBnnnmGX311Vc6duyYOnbsqAcffFBPPvlknWfOBpoaAggAYIJrQAAAEwQQAMBEg3szuqamRocOHVJcXFxEpiQBANQv55wqKiqUlpZ2wa+Eb3ABdOjQIe4SAoAm4MCBA2rfvv15n29wb8FdyqfMAQAN38V+nkctgBYtWqTOnTurVatWysjI0BdffHFJdbztBgBNw8V+nkclgN5++23Nnj1b8+bNC30hVnZ2to4cORKNzQEAGiMXBf3793e5ubmhx2fOnHFpaWkuLy/vorWBQMBJYjAYDEYjH4FA4II/7yN+BnTq1Clt27Yt9PXAkhQbG6usrCxt2rTpnPWrqqoUDAbDBgCg6Yt4AH333Xc6c+aMkpOTw5YnJyertLT0nPXz8vLk9/tDgzvgAODKYH4X3Jw5cxQIBELjwIED1i0BAOpBxD8HlJiYqGbNmqmsrCxseVlZmVJSUs5Z3+fzyefzRboNAEADF/EzoJYtW6pv375av359aFlNTY3Wr1+vzMzMSG8OANBIRWUmhNmzZ2vChAnq16+f+vfvr4ULF+r48eOaNGlSNDYHAGiEohJA9913n/773/9q7ty5Ki0t1U9/+lOtW7funBsTAABXrgb3fUDBYFB+v9+6DQDAZQoEAoqPjz/v8+Z3wQEArkwEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATDS3bgCIhhtuuKFOdS1atPBcM3DgQM81ixcv9lxTU1PjuaYpWr16teeacePG1Wlbp06dqlMdLg1nQAAAEwQQAMBExANo/vz5iomJCRs9evSI9GYAAI1cVK4B3XTTTfr444//t5HmXGoCAISLSjI0b95cKSkp0XhpAEATEZVrQHv27FFaWpq6dOmi8ePHa//+/eddt6qqSsFgMGwAAJq+iAdQRkaG8vPztW7dOi1ZskQlJSW6/fbbVVFRUev6eXl58vv9odGhQ4dItwQAaIAiHkA5OTm699571bt3b2VnZ+vDDz9UeXm53nnnnVrXnzNnjgKBQGgcOHAg0i0BABqgqN8d0K5dO91www0qLi6u9XmfzyefzxftNgAADUzUPwd07Ngx7d27V6mpqdHeFACgEYl4AD322GMqKirSt99+q3/84x+655571KxZM91///2R3hQAoBGL+FtwBw8e1P3336+jR4/q2muv1YABA7R582Zde+21kd4UAKARi3HOOesmfigYDMrv91u3gSi56aabPNdMnDjRc829997ruUaSYmO9vymQlpbmuSYmJsZzTQP7r9qoLFu2rE51M2fO9FzDR0n+JxAIKD4+/rzPMxccAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAE0xGinq1Zs0azzUjRoyIQie2mIy0cRg0aJDnms8//zwKnTROTEYKAGiQCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmmls3gCtLQUGB55r6nA37yJEjnmtee+01zzWxsd5/96upqfFcU1f/93//57mmLjNH48rGGRAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATMc45Z93EDwWDQfn9fus2ECXNm3uf/zY1NTUKndSuurrac01paWkUOrEVHx/vuWbXrl2ea9LS0jzX1MWqVavqVDd+/HjPNVVVVXXaVlMUCAQueCxxBgQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMCE95khgctw+vRpzzUHDhyIQie4kOzsbM81V199dRQ6iYyDBw/WqY6JRaOLMyAAgAkCCABgwnMAbdy4USNHjlRaWppiYmLO+Z4N55zmzp2r1NRUtW7dWllZWdqzZ0+k+gUANBGeA+j48ePq06ePFi1aVOvzCxYs0EsvvaRXXnlFW7ZsUdu2bZWdna3KysrLbhYA0HR4vgkhJydHOTk5tT7nnNPChQv11FNPadSoUZKkZcuWKTk5WatWrdK4ceMur1sAQJMR0WtAJSUlKi0tVVZWVmiZ3+9XRkaGNm3aVGtNVVWVgsFg2AAANH0RDaDS0lJJUnJyctjy5OTk0HM/lpeXJ7/fHxodOnSIZEsAgAbK/C64OXPmKBAIhAaf+QCAK0NEAyglJUWSVFZWFra8rKws9NyP+Xw+xcfHhw0AQNMX0QBKT09XSkqK1q9fH1oWDAa1ZcsWZWZmRnJTAIBGzvNdcMeOHVNxcXHocUlJiXbs2KGEhAR17NhRM2fO1HPPPafrr79e6enpevrpp5WWlqbRo0dHsm8AQCPnOYC2bt2qIUOGhB7Pnj1bkjRhwgTl5+friSee0PHjxzVlyhSVl5drwIABWrdunVq1ahW5rgEAjV6Mc85ZN/FDwWBQfr/fug2gSajrZ+8mT57suWbQoEF12lZ9SEhIqFMdHwu5PIFA4ILX9c3vggMAXJkIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACY8fx0DgMs3fvx4zzW/+c1vPNd069bNc40ktWjRok519WHHjh2ea6qrqyPfCC4bZ0AAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMMBkp6lXnzp091zz44IOea7KysjzX1KcBAwZ4rnHORaGTyAkGg55r6jLB6ocffui55uTJk55rEH2cAQEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADDBZKSos549e3quWbNmjeeajh07eq5B/fv0008917z66qtR6ASNBWdAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATDAZKepVTExMvdQ0dLGx3n/3q6mpiUInkXPXXXd5rsnJyfFcs3btWs81aJg4AwIAmCCAAAAmPAfQxo0bNXLkSKWlpSkmJkarVq0Ke37ixImKiYkJG8OHD49UvwCAJsJzAB0/flx9+vTRokWLzrvO8OHDdfjw4dBYsWLFZTUJAGh6PN+EkJOTc9ELhz6fTykpKXVuCgDQ9EXlGlBhYaGSkpLUvXt3TZs2TUePHj3vulVVVQoGg2EDAND0RTyAhg8frmXLlmn9+vV6/vnnVVRUpJycHJ05c6bW9fPy8uT3+0OjQ4cOkW4JANAARfxzQOPGjQv9uVevXurdu7e6du2qwsJCDR069Jz158yZo9mzZ4ceB4NBQggArgBRvw27S5cuSkxMVHFxca3P+3w+xcfHhw0AQNMX9QA6ePCgjh49qtTU1GhvCgDQiHh+C+7YsWNhZzMlJSXasWOHEhISlJCQoGeeeUZjx45VSkqK9u7dqyeeeELdunVTdnZ2RBsHADRungNo69atGjJkSOjx99dvJkyYoCVLlmjnzp3661//qvLycqWlpWnYsGH63e9+J5/PF7muAQCNXoxzzlk38UPBYFB+v9+6DURJp06dPNc88MADnmv+/ve/e66RpMrKyjrVNVQPPfRQnepmzJgR4U5qN3LkSM81TEbaeAQCgQte12cuOACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACWbDBpqwuv5fOnr0aIQ7qR2zYTdtzIYNAGiQCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmGhu3QCA6MnOzrZuATgvzoAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYYDLSJqZFixaea4YNG1anbW3YsMFzzcmTJ+u0LUiTJk3yXPPHP/4xCp0AkcEZEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABNMRtqADRgwwHPNk08+6bnm5z//uecaSUpPT/dcc+DAgTptqyFLSEjwXDNixAjPNS+88ILnmjZt2niuqau6TDRbWVkZhU7QWHAGBAAwQQABAEx4CqC8vDzdcsstiouLU1JSkkaPHq3du3eHrVNZWanc3Fxdc801uuqqqzR27FiVlZVFtGkAQOPnKYCKioqUm5urzZs3q6CgQNXV1Ro2bJiOHz8eWmfWrFl6//339e6776qoqEiHDh3SmDFjIt44AKBx83QTwrp168Ie5+fnKykpSdu2bdPAgQMVCAT02muvafny5brjjjskSUuXLtWNN96ozZs369Zbb41c5wCARu2yrgEFAgFJ/7sLaNu2baqurlZWVlZonR49eqhjx47atGlTra9RVVWlYDAYNgAATV+dA6impkYzZ87Ubbfdpp49e0qSSktL1bJlS7Vr1y5s3eTkZJWWltb6Onl5efL7/aHRoUOHurYEAGhE6hxAubm52rVrl956663LamDOnDkKBAKh0RQ/JwIAOFedPog6ffp0ffDBB9q4caPat28fWp6SkqJTp06pvLw87CyorKxMKSkptb6Wz+eTz+erSxsAgEbM0xmQc07Tp0/XypUrtWHDhnM+Cd+3b1+1aNFC69evDy3bvXu39u/fr8zMzMh0DABoEjydAeXm5mr58uVavXq14uLiQtd1/H6/WrduLb/fr4ceekizZ89WQkKC4uPjNWPGDGVmZnIHHAAgjKcAWrJkiSRp8ODBYcuXLl2qiRMnSpJefPFFxcbGauzYsaqqqlJ2drYWL14ckWYBAE1HjHPOWTfxQ8FgUH6/37qNBmHHjh2ea76/I7E+fP8LiRcVFRVR6MRWXSZzvfnmmz3X1Od/1cLCQs81dTke/va3v3muQeMRCAQUHx9/3ueZCw4AYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYKJO34gKSNK0adOsW7iiHDlyxHPN+++/X6dtPfroo55rKisr67QtXLk4AwIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCyUgbsIkTJ3qumTFjhueaCRMmeK5pqvbu3eu55sSJE55rPv30U881r776queaXbt2ea4B6gtnQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEzEOOecdRM/FAwG5ff7rdtotHw+n+eaukx6KknPPfec55qrr77ac82qVas81xQUFHiukaTVq1d7riktLa3TtoCmLhAIKD4+/rzPcwYEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABJORAgCigslIAQANEgEEADDhKYDy8vJ0yy23KC4uTklJSRo9erR2794dts7gwYMVExMTNqZOnRrRpgEAjZ+nACoqKlJubq42b96sgoICVVdXa9iwYTp+/HjYepMnT9bhw4dDY8GCBRFtGgDQ+DX3svK6devCHufn5yspKUnbtm3TwIEDQ8vbtGmjlJSUyHQIAGiSLusaUCAQkCQlJCSELX/zzTeVmJionj17as6cOTpx4sR5X6OqqkrBYDBsAACuAK6Ozpw54+6880532223hS3/05/+5NatW+d27tzp3njjDXfddde5e+6557yvM2/ePCeJwWAwGE1sBAKBC+ZInQNo6tSprlOnTu7AgQMXXG/9+vVOkisuLq71+crKShcIBELjwIED5juNwWAwGJc/LhZAnq4BfW/69On64IMPtHHjRrVv3/6C62ZkZEiSiouL1bVr13Oe9/l88vl8dWkDANCIeQog55xmzJihlStXqrCwUOnp6Ret2bFjhyQpNTW1Tg0CAJomTwGUm5ur5cuXa/Xq1YqLi1Npaakkye/3q3Xr1tq7d6+WL1+uESNG6JprrtHOnTs1a9YsDRw4UL17947KXwAA0Eh5ue6j87zPt3TpUuecc/v373cDBw50CQkJzufzuW7durnHH3/8ou8D/lAgEDB/35LBYDAYlz8u9rOfyUgBAFHBZKQAgAaJAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCiwQWQc866BQBABFzs53mDC6CKigrrFgAAEXCxn+cxroGdctTU1OjQoUOKi4tTTExM2HPBYFAdOnTQgQMHFB8fb9ShPfbDWeyHs9gPZ7EfzmoI+8E5p4qKCqWlpSk29vznOc3rsadLEhsbq/bt219wnfj4+Cv6APse++Es9sNZ7Iez2A9nWe8Hv99/0XUa3FtwAIArAwEEADDRqALI5/Np3rx58vl81q2YYj+cxX44i/1wFvvhrMa0HxrcTQgAgCtDozoDAgA0HQQQAMAEAQQAMEEAAQBMEEAAABONJoAWLVqkzp07q1WrVsrIyNAXX3xh3VK9mz9/vmJiYsJGjx49rNuKuo0bN2rkyJFKS0tTTEyMVq1aFfa8c05z585VamqqWrduraysLO3Zs8em2Si62H6YOHHiOcfH8OHDbZqNkry8PN1yyy2Ki4tTUlKSRo8erd27d4etU1lZqdzcXF1zzTW66qqrNHbsWJWVlRl1HB2Xsh8GDx58zvEwdepUo45r1ygC6O2339bs2bM1b948ffnll+rTp4+ys7N15MgR69bq3U033aTDhw+HxmeffWbdUtQdP35cffr00aJFi2p9fsGCBXrppZf0yiuvaMuWLWrbtq2ys7NVWVlZz51G18X2gyQNHz487PhYsWJFPXYYfUVFRcrNzdXmzZtVUFCg6upqDRs2TMePHw+tM2vWLL3//vt69913VVRUpEOHDmnMmDGGXUfepewHSZo8eXLY8bBgwQKjjs/DNQL9+/d3ubm5ocdnzpxxaWlpLi8vz7Cr+jdv3jzXp08f6zZMSXIrV64MPa6pqXEpKSnuD3/4Q2hZeXm58/l8bsWKFQYd1o8f7wfnnJswYYIbNWqUST9Wjhw54iS5oqIi59zZf/sWLVq4d999N7TO119/7SS5TZs2WbUZdT/eD845N2jQIPfoo4/aNXUJGvwZ0KlTp7Rt2zZlZWWFlsXGxiorK0ubNm0y7MzGnj17lJaWpi5dumj8+PHav3+/dUumSkpKVFpaGnZ8+P1+ZWRkXJHHR2FhoZKSktS9e3dNmzZNR48etW4pqgKBgCQpISFBkrRt2zZVV1eHHQ89evRQx44dm/Tx8OP98L0333xTiYmJ6tmzp+bMmaMTJ05YtHdeDW427B/77rvvdObMGSUnJ4ctT05O1jfffGPUlY2MjAzl5+ere/fuOnz4sJ555hndfvvt2rVrl+Li4qzbM1FaWipJtR4f3z93pRg+fLjGjBmj9PR07d27V7/97W+Vk5OjTZs2qVmzZtbtRVxNTY1mzpyp2267TT179pR09nho2bKl2rVrF7ZuUz4eatsPkvTLX/5SnTp1Ulpamnbu3Klf//rX2r17t9577z3DbsM1+ADC/+Tk5IT+3Lt3b2VkZKhTp05655139NBDDxl2hoZg3LhxoT/36tVLvXv3VteuXVVYWKihQ4cadhYdubm52rVr1xVxHfRCzrcfpkyZEvpzr169lJqaqqFDh2rv3r3q2rVrfbdZqwb/FlxiYqKaNWt2zl0sZWVlSklJMeqqYWjXrp1uuOEGFRcXW7di5vtjgOPjXF26dFFiYmKTPD6mT5+uDz74QJ988knY94elpKTo1KlTKi8vD1u/qR4P59sPtcnIyJCkBnU8NPgAatmypfr27av169eHltXU1Gj9+vXKzMw07MzesWPHtHfvXqWmplq3YiY9PV0pKSlhx0cwGNSWLVuu+OPj4MGDOnr0aJM6Ppxzmj59ulauXKkNGzYoPT097Pm+ffuqRYsWYcfD7t27tX///iZ1PFxsP9Rmx44dktSwjgfruyAuxVtvveV8Pp/Lz893X331lZsyZYpr166dKy0ttW6tXv3qV79yhYWFrqSkxH3++ecuKyvLJSYmuiNHjli3FlUVFRVu+/btbvv27U6Se+GFF9z27dvdvn37nHPO/f73v3ft2rVzq1evdjt37nSjRo1y6enp7uTJk8adR9aF9kNFRYV77LHH3KZNm1xJSYn7+OOP3c033+yuv/56V1lZad16xEybNs35/X5XWFjoDh8+HBonTpwIrTN16lTXsWNHt2HDBrd161aXmZnpMjMzDbuOvIvth+LiYvfss8+6rVu3upKSErd69WrXpUsXN3DgQOPOwzWKAHLOuZdfftl17NjRtWzZ0vXv399t3rzZuqV6d99997nU1FTXsmVLd91117n77rvPFRcXW7cVdZ988omTdM6YMGGCc+7srdhPP/20S05Odj6fzw0dOtTt3r3btukouNB+OHHihBs2bJi79tprXYsWLVynTp3c5MmTm9wvabX9/SW5pUuXhtY5efKke/jhh93VV1/t2rRp4+655x53+PBhu6aj4GL7Yf/+/W7gwIEuISHB+Xw+161bN/f444+7QCBg2/iP8H1AAAATDf4aEACgaSKAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACAif8HvjlMuakdda4AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualizing data\n",
    "# Printing an array\n",
    "def printArr(idx):\n",
    "    to_write = \"\"\n",
    "    for i in range(28):\n",
    "        for j in range(28):\n",
    "            if(len(str(imageTrain[idx][i][j])) == 1):\n",
    "                to_write += str(imageTrain[idx][i][j]) + \"    \"\n",
    "            elif(len(str(imageTrain[idx][i][j])) == 2):\n",
    "                to_write += str(imageTrain[idx][i][j]) + \"   \"\n",
    "            else:\n",
    "                to_write += str(imageTrain[idx][i][j]) + \"  \"\n",
    "        to_write += \"\\n\"\n",
    "    to_write += f\"\\nDigit: {labelTrain[idx]}\"\n",
    "    with open(\"./test/imageArr.txt\", \"w\") as file:\n",
    "        file.write(to_write)\n",
    "        \n",
    "# Plotting an image\n",
    "def plotImage(idx):\n",
    "    pyplot.title(f\"Digit {labelTrain[idx]}\")\n",
    "    pyplot.imshow(imageTrain[idx], cmap='gray')\n",
    "    pyplot.savefig(\"./test/digitGrey.jpg\")\n",
    "\n",
    "idx = 7\n",
    "printArr(idx)\n",
    "plotImage(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing data (normalizing image arrays and 1-hot encoding label arrays)\n",
    "# imageTest = np.reshape(imageTest, (10000, 784))\n",
    "# imageTest = preprocessing.normalize(imageTest, norm = \"max\")\n",
    "labelTest = tf.keras.utils.to_categorical(labelTest, num_classes=10)\n",
    "\n",
    "# imageValid = np.reshape(imageValid, (5000, 784))\n",
    "# imageValid = preprocessing.normalize(imageValid, norm = \"max\")\n",
    "labelValid = tf.keras.utils.to_categorical(labelValid, num_classes=10)\n",
    "\n",
    "# imageTrain = np.reshape(imageTrain, (55000, 784))\n",
    "# imageTrain = preprocessing.normalize(imageTrain, norm=\"max\")\n",
    "labelTrain = tf.keras.utils.to_categorical(labelTrain, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing a convolutional neural network with 1 convolution layer and 1 pooling layer\n",
    "class CNN:\n",
    "    def __init__(self, batchSize, iterations, learningRate):\n",
    "        # Initializing model hyperparameters\n",
    "        self.batchSize, self.iterations, self.learningRate = batchSize, iterations, learningRate\n",
    "        self.stride = 1          # Stride for convolution layer\n",
    "        self.padding = 0         # Padding for convolution layer\n",
    "        self.kernelDim = 3       # Dimension of kernel = 3 x 3\n",
    "        self.kernelNum = 5       # Number of kernels (filters)\n",
    "        self.inputDim = 28       # Dimension of input images = 28 x 28\n",
    "        self.featureDim = 26     # Dimension of feature map = inputDim + 2 * padding - kernelDim) / stride + 1 \n",
    "        self.outputDim = 10      # Dimension of output results = 10 x 1\n",
    "        self.sizeTest = 10000    # Size of test set\n",
    "        self.sizeValid = 5000    # Size of validation set\n",
    "        self.sizeTrain = 55000   # Size of training set\n",
    "    \n",
    "    # Convolution layer\n",
    "    def convolutionFF(self, x, kernel):\n",
    "        result = np.zeros((self.kernelNum, self.featureDim, self.featureDim))\n",
    "\n",
    "        for n in range(self.kernelNum):\n",
    "            for i in range(self.featureDim):\n",
    "                for j in range(self.featureDim):\n",
    "                    result[n, i, j] = np.sum(np.multiply(kernel[n], x[i : i + self.kernelDim, j : j + self.kernelDim]))\n",
    "        return result\n",
    "    \n",
    "    def convolutionBP(self, x, kernel):\n",
    "        result = np.zeros((1, self.kernelDim, self.kernelDim))\n",
    "        for n in range(1):\n",
    "            for i in range(self.kernelDim):\n",
    "                for j in range(self.kernelDim):\n",
    "                    result[n, i, j] = np.sum(np.multiply(kernel[n], x[i : i + self.featureDim, j : j + self.featureDim]))\n",
    "        return result.reshape(3, 3)\n",
    "    \n",
    "    # Nonlinear layer using ReLU activation\n",
    "    def relu(self, x):\n",
    "        return x*(x > 0)\n",
    "    \n",
    "    def softmax(self, x):\n",
    "        c = np.max(x, axis = 0, keepdims=True)\n",
    "        x -= c\n",
    "        e = np.exp(x)\n",
    "        return e / np.sum(e, axis = 0, keepdims=True)\n",
    "    \n",
    "    def forwardfeed(self, x):\n",
    "        v = self.convolutionFF(x, self.kernelList) # Feature map\n",
    "        a = (self.relu(v)).reshape(self.kernelNum * self.featureDim ** 2, 1) # Feature map after ReLU\n",
    "        z = np.dot(self.w, a) + self.b\n",
    "        yCal = self.softmax(z)\n",
    "        return (v, a, z, yCal)\n",
    "    \n",
    "    def backpropagation(self, x, yLabel, v, a, z, yCal):        \n",
    "        e2 = (yCal - yLabel) / self.batchSize # gradient of softmax using cross entropy\n",
    "        db = np.sum(e2, axis=1, keepdims=True)\n",
    "        dw = np.dot(a, e2.T).T\n",
    "        e1 = np.dot(self.w.T, e2)\n",
    "        e1 = e1.reshape(5, 26, 26)\n",
    "        e1[v <= 0] = 0\n",
    "        dk = []\n",
    "        for i in range(5):\n",
    "            tmp_arr = np.multiply(v[i], e1[i])\n",
    "            dk.append(self.convolutionBP(x, tmp_arr))\n",
    "        \n",
    "        return (db, dw, dk)\n",
    "    \n",
    "    def lossCE(self, yCal, yLabel):\n",
    "        result = -np.sum(np.log(yCal) * yLabel) / self.batchSize\n",
    "        return result\n",
    "    \n",
    "    def train(self, xTrain, yTrain):\n",
    "        # Initializing random weights and biases for output layer\n",
    "        self.w = 0.0001 * np.random.rand(self.outputDim, self.kernelNum * self.featureDim ** 2)\n",
    "        self.b = 0.0001 * np.random.rand(self.outputDim, 1)\n",
    "        # Initializing random kernels for convolution layer\n",
    "        self.kernelList = []\n",
    "        for n in range(self.kernelNum):\n",
    "            kernel = 0.0001 * np.random.rand(self.kernelDim, self.kernelDim)\n",
    "            self.kernelList.append(kernel)\n",
    "        \n",
    "        # Generating a random list of indices for mini BGD\n",
    "        idxList = np.random.randint(low=0, high=self.sizeTrain, size=self.batchSize)\n",
    "\n",
    "        count = 0\n",
    "        for n in range(self.iterations):\n",
    "            for idx in idxList:\n",
    "                x = xTrain[idx]\n",
    "                yLabel = yTrain[idx]\n",
    "                v, a, z, yCal = self.forwardfeed(x)\n",
    "                loss = self.lossCE(yCal, yLabel)\n",
    "                db, dw, dk = self.backpropagation(x, yLabel.reshape(10, 1), v, a, z, yCal)\n",
    "                \n",
    "                #Updating weight, biases and kernels\n",
    "                self.w += self.learningRate * dw\n",
    "                self.b += self.learningRate * db\n",
    "                for idx in range(self.kernelNum):\n",
    "                    self.kernelList[idx] += self.learningRate * dk[idx]\n",
    "                \n",
    "            if n % 100 == 0:\n",
    "                    print(f\"[Iter {n}] Loss: {loss}\\n\")\n",
    "\n",
    "        print(\"Training finished!\")\n",
    "    \n",
    "    def test(self, xValid, yValid):\n",
    "        correct = 0\n",
    "        for n in range(100):\n",
    "            x = xValid[n]\n",
    "            yLabel = yValid[n]\n",
    "            (v, a, z, yCal) = self.forwardfeed(x)\n",
    "            prediction = np.argmax(yCal)\n",
    "            answer = np.argmax(yLabel)\n",
    "            print(prediction, answer)\n",
    "            if (prediction == answer):\n",
    "                correct += 1\n",
    "                \n",
    "        print(f\"Accuarcy: {correct / 100}\")\n",
    "        \n",
    "model = CNN(batchSize=1, iterations=1000, learningRate=0.01)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iter 0] Loss: 23.025850952488113\n",
      "\n",
      "[Iter 100] Loss: 27.584722265176133\n",
      "\n",
      "[Iter 200] Loss: 33.302259177993704\n",
      "\n",
      "[Iter 300] Loss: 39.0242597095683\n",
      "\n",
      "[Iter 400] Loss: 44.746275706086934\n",
      "\n",
      "[Iter 500] Loss: 50.46829440158156\n",
      "\n",
      "[Iter 600] Loss: 56.19032139375504\n",
      "\n",
      "[Iter 700] Loss: 61.912374343659\n",
      "\n",
      "[Iter 800] Loss: 67.63450847860412\n",
      "\n",
      "[Iter 900] Loss: 73.35689637040834\n",
      "\n",
      "Training finished!\n"
     ]
    }
   ],
   "source": [
    "model.train(imageTrain, labelTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 1\n",
      "2 2\n",
      "2 8\n",
      "2 7\n",
      "2 4\n",
      "2 4\n",
      "2 0\n",
      "2 9\n",
      "2 3\n",
      "2 9\n",
      "2 5\n",
      "2 2\n",
      "2 6\n",
      "2 9\n",
      "2 1\n",
      "2 8\n",
      "2 6\n",
      "2 3\n",
      "2 6\n",
      "2 6\n",
      "2 8\n",
      "2 7\n",
      "2 8\n",
      "2 0\n",
      "2 4\n",
      "2 4\n",
      "2 8\n",
      "2 0\n",
      "2 3\n",
      "2 0\n",
      "2 0\n",
      "2 1\n",
      "2 2\n",
      "2 2\n",
      "2 7\n",
      "2 3\n",
      "2 1\n",
      "2 4\n",
      "2 3\n",
      "2 6\n",
      "2 2\n",
      "2 7\n",
      "2 5\n",
      "2 8\n",
      "2 2\n",
      "2 0\n",
      "2 1\n",
      "2 1\n",
      "2 0\n",
      "2 2\n",
      "2 3\n",
      "2 3\n",
      "2 7\n",
      "2 4\n",
      "2 3\n",
      "2 5\n",
      "2 0\n",
      "2 6\n",
      "2 5\n",
      "2 7\n",
      "2 5\n",
      "2 8\n",
      "2 3\n",
      "2 9\n",
      "2 9\n",
      "2 0\n",
      "2 6\n",
      "2 1\n",
      "2 9\n",
      "2 2\n",
      "2 2\n",
      "2 3\n",
      "2 9\n",
      "2 4\n",
      "2 4\n",
      "2 5\n",
      "2 5\n",
      "2 6\n",
      "2 7\n",
      "2 7\n",
      "2 1\n",
      "2 8\n",
      "2 7\n",
      "2 1\n",
      "2 7\n",
      "2 4\n",
      "2 7\n",
      "2 4\n",
      "2 7\n",
      "2 2\n",
      "2 7\n",
      "2 3\n",
      "2 9\n",
      "2 3\n",
      "2 7\n",
      "2 0\n",
      "2 6\n",
      "2 9\n",
      "2 4\n",
      "2 5\n",
      "Accuarcy: 0.1\n"
     ]
    }
   ],
   "source": [
    "model.test(imageValid, labelValid)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f2ec3a27b206c5c715624a547105f4453c6ed312d93e4b85e955c3b1a3db3dae"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
