{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from matplotlib import pyplot\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the MNIST datasets - 60000 images for training and 10000 images for testing\n",
    "(imageTrain, labelTrain), (imageTest, labelTest) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# Splitting the training set into 2: 55000 images for training and 5000 images for validation\n",
    "imageTest = imageTest[:]\n",
    "labelTest = labelTest[:]\n",
    "\n",
    "imageValid = imageTrain[55000:]\n",
    "labelValid = labelTrain[55000:]\n",
    "\n",
    "imageTrain = imageTrain[:55000]\n",
    "labelTrain = labelTrain[:55000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGzCAYAAABpdMNsAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8o6BhiAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAgRUlEQVR4nO3de3BU9fnH8U/CZbmYLMaYm9wCKFi5tILE/EQukhKCIgh1xKIDjAMDBhSo2lIV0DqTSmeU6gDWqSVFBS9TuegINYIJagEHhDJUpYSJXAoJlZnshktCIN/fH4xbV8LlhN08SXi/Zr4z7Nnz7Hk4HPLJ2XP2uzHOOScAAOpZrHUDAIArEwEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQRcpvnz5ysmJqZOtfn5+YqJidG3334b2aaARoAAAn7g+0D4frRq1UppaWnKzs7WSy+9pIqKiqj3sHjxYuXn51/y+rNmzdLNN9+shIQEtWnTRjfeeKPmz5+vY8eORa9JIAJimAsO+J/8/HxNmjRJzz77rNLT01VdXa3S0lIVFhaqoKBAHTt21Jo1a9S7d+9QzenTp3X69Gm1atXK8/bOnDmj6upq+Xy+0FlUz549lZiYqMLCwkt6jQEDBqhv377q1q2bWrVqpe3bt+svf/mL+vXrp40bNyo2lt8z0TA1t24AaIhycnLUr1+/0OM5c+Zow4YNuuuuu3T33Xfr66+/VuvWrSVJzZs3V/Pmdfuv1KxZMzVr1uyyev3ss8/OWda1a1c99thj+uKLL3Trrbde1usD0cKvRsAluuOOO/T0009r3759euONN0LLa7sGdPLkST3yyCNKTExUXFyc7r77bv3nP/9RTEyM5s+fH1rvx9eAOnfurH/9618qKioKvQ04ePBgz7127txZklReXu65FqgvBBDgwYMPPihJ+uijjy643sSJE/Xyyy9rxIgRev7559W6dWvdeeedF339hQsXqn379urRo4def/11vf7663ryyScvWnf69Gl99913OnTokD766CM99dRTiouLU//+/S/tLwYY4C04wIP27dvL7/dr7969513nyy+/1DvvvKOZM2fqxRdflCQ9/PDDmjRpkv75z39e8PVHjx6tp556SomJiXrggQcuua+tW7cqMzMz9Lh79+5as2aNEhISLvk1gPrGGRDg0VVXXXXBu+HWrVsn6Wzo/NCMGTOi1tNPfvITFRQUaNWqVXriiSfUtm1b7oJDg8cZEODRsWPHlJSUdN7n9+3bp9jYWKWnp4ct79atW9R6io+PV1ZWliRp1KhRWr58uUaNGqUvv/xSffr0idp2gcvBGRDgwcGDBxUIBKIaJpEwZswYSdJbb71l3AlwfgQQ4MHrr78uScrOzj7vOp06dVJNTY1KSkrClhcXF1/SNuo6q8IPVVVVqaamRoFA4LJfC4gWAgi4RBs2bNDvfvc7paena/z48edd7/twWrx4cdjyl19++ZK207Zt20u+fbq8vFzV1dXnLP/zn/8sSWGfZQIaGq4BAbVYu3atvvnmG50+fVplZWXasGGDCgoK1KlTJ61Zs+aCsx707dtXY8eO1cKFC3X06FHdeuutKioq0r///W9JFz/D6du3r5YsWaLnnntO3bp1U1JSku64445a1y0sLNQjjzyiX/ziF7r++ut16tQpffrpp3rvvffUr18/T3fSAfWNAAJqMXfuXElSy5YtlZCQoF69emnhwoWaNGmS4uLiLlq/bNkypaSkaMWKFVq5cqWysrL09ttvq3v37hedsmfu3Lnat2+fFixYoIqKCg0aNOi8AdSrVy8NGTJEq1ev1uHDh+WcU9euXTV37lw9/vjjatmypfe/PFBPmAsOqCc7duzQz372M73xxhsXfAsPuFJwDQiIgpMnT56zbOHChYqNjdXAgQMNOgIaHt6CA6JgwYIF2rZtm4YMGaLmzZtr7dq1Wrt2raZMmaIOHTpYtwc0CLwFB0RBQUGBnnnmGX311Vc6duyYOnbsqAcffFBPPvlknWfOBpoaAggAYIJrQAAAEwQQAMBEg3szuqamRocOHVJcXFxEpiQBANQv55wqKiqUlpZ2wa+Eb3ABdOjQIe4SAoAm4MCBA2rfvv15n29wb8FdyqfMAQAN38V+nkctgBYtWqTOnTurVatWysjI0BdffHFJdbztBgBNw8V+nkclgN5++23Nnj1b8+bNC30hVnZ2to4cORKNzQEAGiMXBf3793e5ubmhx2fOnHFpaWkuLy/vorWBQMBJYjAYDEYjH4FA4II/7yN+BnTq1Clt27Yt9PXAkhQbG6usrCxt2rTpnPWrqqoUDAbDBgCg6Yt4AH333Xc6c+aMkpOTw5YnJyertLT0nPXz8vLk9/tDgzvgAODKYH4X3Jw5cxQIBELjwIED1i0BAOpBxD8HlJiYqGbNmqmsrCxseVlZmVJSUs5Z3+fzyefzRboNAEADF/EzoJYtW6pv375av359aFlNTY3Wr1+vzMzMSG8OANBIRWUmhNmzZ2vChAnq16+f+vfvr4ULF+r48eOaNGlSNDYHAGiEohJA9913n/773/9q7ty5Ki0t1U9/+lOtW7funBsTAABXrgb3fUDBYFB+v9+6DQDAZQoEAoqPjz/v8+Z3wQEArkwEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATDS3bgCIhhtuuKFOdS1atPBcM3DgQM81ixcv9lxTU1PjuaYpWr16teeacePG1Wlbp06dqlMdLg1nQAAAEwQQAMBExANo/vz5iomJCRs9evSI9GYAAI1cVK4B3XTTTfr444//t5HmXGoCAISLSjI0b95cKSkp0XhpAEATEZVrQHv27FFaWpq6dOmi8ePHa//+/eddt6qqSsFgMGwAAJq+iAdQRkaG8vPztW7dOi1ZskQlJSW6/fbbVVFRUev6eXl58vv9odGhQ4dItwQAaIAiHkA5OTm699571bt3b2VnZ+vDDz9UeXm53nnnnVrXnzNnjgKBQGgcOHAg0i0BABqgqN8d0K5dO91www0qLi6u9XmfzyefzxftNgAADUzUPwd07Ngx7d27V6mpqdHeFACgEYl4AD322GMqKirSt99+q3/84x+655571KxZM91///2R3hQAoBGL+FtwBw8e1P3336+jR4/q2muv1YABA7R582Zde+21kd4UAKARi3HOOesmfigYDMrv91u3gSi56aabPNdMnDjRc829997ruUaSYmO9vymQlpbmuSYmJsZzTQP7r9qoLFu2rE51M2fO9FzDR0n+JxAIKD4+/rzPMxccAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAE0xGinq1Zs0azzUjRoyIQie2mIy0cRg0aJDnms8//zwKnTROTEYKAGiQCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmmls3gCtLQUGB55r6nA37yJEjnmtee+01zzWxsd5/96upqfFcU1f/93//57mmLjNH48rGGRAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATMc45Z93EDwWDQfn9fus2ECXNm3uf/zY1NTUKndSuurrac01paWkUOrEVHx/vuWbXrl2ea9LS0jzX1MWqVavqVDd+/HjPNVVVVXXaVlMUCAQueCxxBgQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMCE95khgctw+vRpzzUHDhyIQie4kOzsbM81V199dRQ6iYyDBw/WqY6JRaOLMyAAgAkCCABgwnMAbdy4USNHjlRaWppiYmLO+Z4N55zmzp2r1NRUtW7dWllZWdqzZ0+k+gUANBGeA+j48ePq06ePFi1aVOvzCxYs0EsvvaRXXnlFW7ZsUdu2bZWdna3KysrLbhYA0HR4vgkhJydHOTk5tT7nnNPChQv11FNPadSoUZKkZcuWKTk5WatWrdK4ceMur1sAQJMR0WtAJSUlKi0tVVZWVmiZ3+9XRkaGNm3aVGtNVVWVgsFg2AAANH0RDaDS0lJJUnJyctjy5OTk0HM/lpeXJ7/fHxodOnSIZEsAgAbK/C64OXPmKBAIhAaf+QCAK0NEAyglJUWSVFZWFra8rKws9NyP+Xw+xcfHhw0AQNMX0QBKT09XSkqK1q9fH1oWDAa1ZcsWZWZmRnJTAIBGzvNdcMeOHVNxcXHocUlJiXbs2KGEhAR17NhRM2fO1HPPPafrr79e6enpevrpp5WWlqbRo0dHsm8AQCPnOYC2bt2qIUOGhB7Pnj1bkjRhwgTl5+friSee0PHjxzVlyhSVl5drwIABWrdunVq1ahW5rgEAjV6Mc85ZN/FDwWBQfr/fug2gSajrZ+8mT57suWbQoEF12lZ9SEhIqFMdHwu5PIFA4ILX9c3vggMAXJkIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACY8fx0DgMs3fvx4zzW/+c1vPNd069bNc40ktWjRok519WHHjh2ea6qrqyPfCC4bZ0AAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMMBkp6lXnzp091zz44IOea7KysjzX1KcBAwZ4rnHORaGTyAkGg55r6jLB6ocffui55uTJk55rEH2cAQEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADDBZKSos549e3quWbNmjeeajh07eq5B/fv0008917z66qtR6ASNBWdAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATDAZKepVTExMvdQ0dLGx3n/3q6mpiUInkXPXXXd5rsnJyfFcs3btWs81aJg4AwIAmCCAAAAmPAfQxo0bNXLkSKWlpSkmJkarVq0Ke37ixImKiYkJG8OHD49UvwCAJsJzAB0/flx9+vTRokWLzrvO8OHDdfjw4dBYsWLFZTUJAGh6PN+EkJOTc9ELhz6fTykpKXVuCgDQ9EXlGlBhYaGSkpLUvXt3TZs2TUePHj3vulVVVQoGg2EDAND0RTyAhg8frmXLlmn9+vV6/vnnVVRUpJycHJ05c6bW9fPy8uT3+0OjQ4cOkW4JANAARfxzQOPGjQv9uVevXurdu7e6du2qwsJCDR069Jz158yZo9mzZ4ceB4NBQggArgBRvw27S5cuSkxMVHFxca3P+3w+xcfHhw0AQNMX9QA6ePCgjh49qtTU1GhvCgDQiHh+C+7YsWNhZzMlJSXasWOHEhISlJCQoGeeeUZjx45VSkqK9u7dqyeeeELdunVTdnZ2RBsHADRungNo69atGjJkSOjx99dvJkyYoCVLlmjnzp3661//qvLycqWlpWnYsGH63e9+J5/PF7muAQCNXoxzzlk38UPBYFB+v9+6DURJp06dPNc88MADnmv+/ve/e66RpMrKyjrVNVQPPfRQnepmzJgR4U5qN3LkSM81TEbaeAQCgQte12cuOACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACWbDBpqwuv5fOnr0aIQ7qR2zYTdtzIYNAGiQCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmGhu3QCA6MnOzrZuATgvzoAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYYDLSJqZFixaea4YNG1anbW3YsMFzzcmTJ+u0LUiTJk3yXPPHP/4xCp0AkcEZEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABNMRtqADRgwwHPNk08+6bnm5z//uecaSUpPT/dcc+DAgTptqyFLSEjwXDNixAjPNS+88ILnmjZt2niuqau6TDRbWVkZhU7QWHAGBAAwQQABAEx4CqC8vDzdcsstiouLU1JSkkaPHq3du3eHrVNZWanc3Fxdc801uuqqqzR27FiVlZVFtGkAQOPnKYCKioqUm5urzZs3q6CgQNXV1Ro2bJiOHz8eWmfWrFl6//339e6776qoqEiHDh3SmDFjIt44AKBx83QTwrp168Ie5+fnKykpSdu2bdPAgQMVCAT02muvafny5brjjjskSUuXLtWNN96ozZs369Zbb41c5wCARu2yrgEFAgFJ/7sLaNu2baqurlZWVlZonR49eqhjx47atGlTra9RVVWlYDAYNgAATV+dA6impkYzZ87Ubbfdpp49e0qSSktL1bJlS7Vr1y5s3eTkZJWWltb6Onl5efL7/aHRoUOHurYEAGhE6hxAubm52rVrl956663LamDOnDkKBAKh0RQ/JwIAOFedPog6ffp0ffDBB9q4caPat28fWp6SkqJTp06pvLw87CyorKxMKSkptb6Wz+eTz+erSxsAgEbM0xmQc07Tp0/XypUrtWHDhnM+Cd+3b1+1aNFC69evDy3bvXu39u/fr8zMzMh0DABoEjydAeXm5mr58uVavXq14uLiQtd1/H6/WrduLb/fr4ceekizZ89WQkKC4uPjNWPGDGVmZnIHHAAgjKcAWrJkiSRp8ODBYcuXLl2qiRMnSpJefPFFxcbGauzYsaqqqlJ2drYWL14ckWYBAE1HjHPOWTfxQ8FgUH6/37qNBmHHjh2ea76/I7E+fP8LiRcVFRVR6MRWXSZzvfnmmz3X1Od/1cLCQs81dTke/va3v3muQeMRCAQUHx9/3ueZCw4AYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYKJO34gKSNK0adOsW7iiHDlyxHPN+++/X6dtPfroo55rKisr67QtXLk4AwIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCyUgbsIkTJ3qumTFjhueaCRMmeK5pqvbu3eu55sSJE55rPv30U881r776queaXbt2ea4B6gtnQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEzEOOecdRM/FAwG5ff7rdtotHw+n+eaukx6KknPPfec55qrr77ac82qVas81xQUFHiukaTVq1d7riktLa3TtoCmLhAIKD4+/rzPcwYEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABJORAgCigslIAQANEgEEADDhKYDy8vJ0yy23KC4uTklJSRo9erR2794dts7gwYMVExMTNqZOnRrRpgEAjZ+nACoqKlJubq42b96sgoICVVdXa9iwYTp+/HjYepMnT9bhw4dDY8GCBRFtGgDQ+DX3svK6devCHufn5yspKUnbtm3TwIEDQ8vbtGmjlJSUyHQIAGiSLusaUCAQkCQlJCSELX/zzTeVmJionj17as6cOTpx4sR5X6OqqkrBYDBsAACuAK6Ozpw54+6880532223hS3/05/+5NatW+d27tzp3njjDXfddde5e+6557yvM2/ePCeJwWAwGE1sBAKBC+ZInQNo6tSprlOnTu7AgQMXXG/9+vVOkisuLq71+crKShcIBELjwIED5juNwWAwGJc/LhZAnq4BfW/69On64IMPtHHjRrVv3/6C62ZkZEiSiouL1bVr13Oe9/l88vl8dWkDANCIeQog55xmzJihlStXqrCwUOnp6Ret2bFjhyQpNTW1Tg0CAJomTwGUm5ur5cuXa/Xq1YqLi1Npaakkye/3q3Xr1tq7d6+WL1+uESNG6JprrtHOnTs1a9YsDRw4UL17947KXwAA0Eh5ue6j87zPt3TpUuecc/v373cDBw50CQkJzufzuW7durnHH3/8ou8D/lAgEDB/35LBYDAYlz8u9rOfyUgBAFHBZKQAgAaJAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCiwQWQc866BQBABFzs53mDC6CKigrrFgAAEXCxn+cxroGdctTU1OjQoUOKi4tTTExM2HPBYFAdOnTQgQMHFB8fb9ShPfbDWeyHs9gPZ7EfzmoI+8E5p4qKCqWlpSk29vznOc3rsadLEhsbq/bt219wnfj4+Cv6APse++Es9sNZ7Iez2A9nWe8Hv99/0XUa3FtwAIArAwEEADDRqALI5/Np3rx58vl81q2YYj+cxX44i/1wFvvhrMa0HxrcTQgAgCtDozoDAgA0HQQQAMAEAQQAMEEAAQBMEEAAABONJoAWLVqkzp07q1WrVsrIyNAXX3xh3VK9mz9/vmJiYsJGjx49rNuKuo0bN2rkyJFKS0tTTEyMVq1aFfa8c05z585VamqqWrduraysLO3Zs8em2Si62H6YOHHiOcfH8OHDbZqNkry8PN1yyy2Ki4tTUlKSRo8erd27d4etU1lZqdzcXF1zzTW66qqrNHbsWJWVlRl1HB2Xsh8GDx58zvEwdepUo45r1ygC6O2339bs2bM1b948ffnll+rTp4+ys7N15MgR69bq3U033aTDhw+HxmeffWbdUtQdP35cffr00aJFi2p9fsGCBXrppZf0yiuvaMuWLWrbtq2ys7NVWVlZz51G18X2gyQNHz487PhYsWJFPXYYfUVFRcrNzdXmzZtVUFCg6upqDRs2TMePHw+tM2vWLL3//vt69913VVRUpEOHDmnMmDGGXUfepewHSZo8eXLY8bBgwQKjjs/DNQL9+/d3ubm5ocdnzpxxaWlpLi8vz7Cr+jdv3jzXp08f6zZMSXIrV64MPa6pqXEpKSnuD3/4Q2hZeXm58/l8bsWKFQYd1o8f7wfnnJswYYIbNWqUST9Wjhw54iS5oqIi59zZf/sWLVq4d999N7TO119/7SS5TZs2WbUZdT/eD845N2jQIPfoo4/aNXUJGvwZ0KlTp7Rt2zZlZWWFlsXGxiorK0ubNm0y7MzGnj17lJaWpi5dumj8+PHav3+/dUumSkpKVFpaGnZ8+P1+ZWRkXJHHR2FhoZKSktS9e3dNmzZNR48etW4pqgKBgCQpISFBkrRt2zZVV1eHHQ89evRQx44dm/Tx8OP98L0333xTiYmJ6tmzp+bMmaMTJ05YtHdeDW427B/77rvvdObMGSUnJ4ctT05O1jfffGPUlY2MjAzl5+ere/fuOnz4sJ555hndfvvt2rVrl+Li4qzbM1FaWipJtR4f3z93pRg+fLjGjBmj9PR07d27V7/97W+Vk5OjTZs2qVmzZtbtRVxNTY1mzpyp2267TT179pR09nho2bKl2rVrF7ZuUz4eatsPkvTLX/5SnTp1Ulpamnbu3Klf//rX2r17t9577z3DbsM1+ADC/+Tk5IT+3Lt3b2VkZKhTp05655139NBDDxl2hoZg3LhxoT/36tVLvXv3VteuXVVYWKihQ4cadhYdubm52rVr1xVxHfRCzrcfpkyZEvpzr169lJqaqqFDh2rv3r3q2rVrfbdZqwb/FlxiYqKaNWt2zl0sZWVlSklJMeqqYWjXrp1uuOEGFRcXW7di5vtjgOPjXF26dFFiYmKTPD6mT5+uDz74QJ988knY94elpKTo1KlTKi8vD1u/qR4P59sPtcnIyJCkBnU8NPgAatmypfr27av169eHltXU1Gj9+vXKzMw07MzesWPHtHfvXqWmplq3YiY9PV0pKSlhx0cwGNSWLVuu+OPj4MGDOnr0aJM6Ppxzmj59ulauXKkNGzYoPT097Pm+ffuqRYsWYcfD7t27tX///iZ1PFxsP9Rmx44dktSwjgfruyAuxVtvveV8Pp/Lz893X331lZsyZYpr166dKy0ttW6tXv3qV79yhYWFrqSkxH3++ecuKyvLJSYmuiNHjli3FlUVFRVu+/btbvv27U6Se+GFF9z27dvdvn37nHPO/f73v3ft2rVzq1evdjt37nSjRo1y6enp7uTJk8adR9aF9kNFRYV77LHH3KZNm1xJSYn7+OOP3c033+yuv/56V1lZad16xEybNs35/X5XWFjoDh8+HBonTpwIrTN16lTXsWNHt2HDBrd161aXmZnpMjMzDbuOvIvth+LiYvfss8+6rVu3upKSErd69WrXpUsXN3DgQOPOwzWKAHLOuZdfftl17NjRtWzZ0vXv399t3rzZuqV6d99997nU1FTXsmVLd91117n77rvPFRcXW7cVdZ988omTdM6YMGGCc+7srdhPP/20S05Odj6fzw0dOtTt3r3btukouNB+OHHihBs2bJi79tprXYsWLVynTp3c5MmTm9wvabX9/SW5pUuXhtY5efKke/jhh93VV1/t2rRp4+655x53+PBhu6aj4GL7Yf/+/W7gwIEuISHB+Xw+161bN/f444+7QCBg2/iP8H1AAAATDf4aEACgaSKAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACAif8HvjlMuakdda4AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualizing data\n",
    "# Printing an array\n",
    "def printArr(idx):\n",
    "    to_write = \"\"\n",
    "    for i in range(28):\n",
    "        for j in range(28):\n",
    "            if(len(str(imageTrain[idx][i][j])) == 1):\n",
    "                to_write += str(imageTrain[idx][i][j]) + \"    \"\n",
    "            elif(len(str(imageTrain[idx][i][j])) == 2):\n",
    "                to_write += str(imageTrain[idx][i][j]) + \"   \"\n",
    "            else:\n",
    "                to_write += str(imageTrain[idx][i][j]) + \"  \"\n",
    "        to_write += \"\\n\"\n",
    "    to_write += f\"\\nDigit: {labelTrain[idx]}\"\n",
    "    with open(\"./test/imageArr.txt\", \"w\") as file:\n",
    "        file.write(to_write)\n",
    "        \n",
    "# Plotting an image\n",
    "def plotImage(idx):\n",
    "    pyplot.title(f\"Digit {labelTrain[idx]}\")\n",
    "    pyplot.imshow(imageTrain[idx], cmap='gray')\n",
    "    pyplot.savefig(\"./test/digitGrey.jpg\")\n",
    "\n",
    "idx = 7\n",
    "printArr(idx)\n",
    "plotImage(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing data (normalizing image arrays and 1-hot encoding label arrays)\n",
    "# imageTest = np.reshape(imageTest, (10000, 784))\n",
    "# imageTest = preprocessing.normalize(imageTest, norm = \"max\")\n",
    "labelTest = tf.keras.utils.to_categorical(labelTest, num_classes=10)\n",
    "\n",
    "# imageValid = np.reshape(imageValid, (5000, 784))\n",
    "# imageValid = preprocessing.normalize(imageValid, norm = \"max\")\n",
    "labelValid = tf.keras.utils.to_categorical(labelValid, num_classes=10)\n",
    "\n",
    "# imageTrain = np.reshape(imageTrain, (55000, 784))\n",
    "# imageTrain = preprocessing.normalize(imageTrain, norm=\"max\")\n",
    "labelTrain = tf.keras.utils.to_categorical(labelTrain, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 26, 26)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shapes (10,3380) and (5,26,26) not aligned: 3380 (dim 1) != 26 (dim 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [69], line 98\u001b[0m\n\u001b[0;32m     95\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m lossDict, tesDict\n\u001b[0;32m     97\u001b[0m model \u001b[38;5;241m=\u001b[39m CNN(batchSize\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m, iterations\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, learningRate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.05\u001b[39m)\n\u001b[1;32m---> 98\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimageTrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabelTrain\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn [69], line 75\u001b[0m, in \u001b[0;36mCNN.train\u001b[1;34m(self, xTrain, yTrain)\u001b[0m\n\u001b[0;32m     72\u001b[0m tesDict \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m idxList:\n\u001b[1;32m---> 75\u001b[0m     resultFF \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforwardfeed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxTrain\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myTrain\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     76\u001b[0m     resultBP \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackpropagation(xTrain[i], yTrain[i], resultFF)\n\u001b[0;32m     78\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mw \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlearningRate \u001b[38;5;241m*\u001b[39m resultBP[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdW\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "Cell \u001b[1;32mIn [69], line 46\u001b[0m, in \u001b[0;36mCNN.forwardfeed\u001b[1;34m(self, x, y)\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28mprint\u001b[39m(v\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m     45\u001b[0m z \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(v) \u001b[38;5;66;03m# Feature map after ReLU\u001b[39;00m\n\u001b[1;32m---> 46\u001b[0m a \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mz\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mb\n\u001b[0;32m     47\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msoftmax(a)\n\u001b[0;32m     48\u001b[0m \u001b[38;5;66;03m#error = self.cross_entropy_error(predict_list, y)\u001b[39;00m\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (10,3380) and (5,26,26) not aligned: 3380 (dim 1) != 26 (dim 1)"
     ]
    }
   ],
   "source": [
    "# Implementing a convolutional neural network with 1 convolution layer and 1 pooling layer\n",
    "class CNN:\n",
    "    def __init__(self, batchSize, iterations, learningRate):\n",
    "        # Initializing model hyperparameters\n",
    "        self.batchSize, self.iterations, self.learningRate = batchSize, iterations, learningRate\n",
    "        self.stride = 1          # Stride for convolution layer\n",
    "        self.padding = 0         # Padding for convolution layer\n",
    "        self.kernelDim = 3       # Dimension of kernel = 3 x 3\n",
    "        self.kernelNum = 5       # Number of kernels (filters)\n",
    "        self.inputDim = 28       # Dimension of input images = 28 x 28\n",
    "        self.featureDim = 26     # Dimension of feature map = inputDim + 2 * padding - kernelDim) / stride + 1 \n",
    "        self.outputDim = 10      # Dimension of output results = 10 x 1\n",
    "        self.sizeTest = 10000    # Size of test set\n",
    "        self.sizeValid = 5000    # Size of validation set\n",
    "        self.sizeTrain = 55000   # Size of training set\n",
    "    \n",
    "    # Convolution layer\n",
    "    def convolution(self, x, kernelList):\n",
    "        result = np.zeros((self.kernelNum, self.featureDim, self.featureDim))\n",
    "        \n",
    "        for n in range(self.kernelNum):\n",
    "            for i in range(self.featureDim):\n",
    "                for j in range(self.featureDim):\n",
    "                    result[n, i, j] = np.sum(np.multiply(kernelList[n], x[i : i + self.kernelDim, j : j + self.kernelDim]))\n",
    "        return result\n",
    "    \n",
    "    # Nonlinear layer using ReLU activation\n",
    "    def relu(self, x):\n",
    "        return np.maximum(x, 0)\n",
    "    \n",
    "    def softmax(self, x):\n",
    "        c = np.max(x, axis = 0, keepdims=True)\n",
    "        x -= c\n",
    "        e = np.exp(x)\n",
    "        return e / np.sum(e, axis = 0, keepdims=True)\n",
    "    \n",
    "    def forwardfeed(self, x, y):\n",
    "        ''' input -- x: training data input x, size of (784,)\n",
    "                     y: training data output y, integer\n",
    "            output-- a dictionary of Z, H, U, f_X, error\n",
    "        '''\n",
    "        v = self.convolution(x, self.kernelList) # Feature map\n",
    "        z = (self.relu(v)).T # Feature map after ReLU\n",
    "        print(z.shape)\n",
    "        a = np.dot(self.w, z) + self.b\n",
    "        y = self.softmax(a)\n",
    "        #error = self.cross_entropy_error(predict_list, y)\n",
    "        return (v, z, a, y)\n",
    "    \n",
    "    def train(self, xTrain, yTrain):\n",
    "        # Initializing random weights and biases for output layer\n",
    "        # Dimension of weight is 10 x 3380 to map convolution layer (x) to output layer (y) \n",
    "        self.w = 0.01 * np.random.randn(self.outputDim, self.kernelNum * self.featureDim ** 2)\n",
    "        # Dimension of bias is 10 x 1\n",
    "        self.b = 0.01 * np.random.randn(self.outputDim, 1)\n",
    "        # Initializing random kernels for convolutional layer\n",
    "        self.kernelList = []\n",
    "        for n in range(self.kernelNum):\n",
    "            kernel = 0.01 * np.random.randn(self.kernelDim, self.kernelDim)\n",
    "            self.kernelList.append(kernel)\n",
    "            \n",
    "        # print(self.W)\n",
    "        # print(self.b)\n",
    "        # print(self.kernelList)\n",
    "        \n",
    "        # Generating a random list of indices for the training set\n",
    "        idxList = np.random.randint(low=0, high=self.sizeTrain, size=self.batchSize)\n",
    "\n",
    "        count = 0\n",
    "        lossDict = {}\n",
    "        tesDict = {}\n",
    "\n",
    "        for i in idxList:\n",
    "            resultFF = self.forwardfeed(xTrain[i], yTrain[i])\n",
    "            resultBP = self.backpropagation(xTrain[i], yTrain[i], resultFF)\n",
    "            \n",
    "            self.w -= self.learningRate * resultBP['dW']\n",
    "            self.b -= self.learningRate * resultBP['db']\n",
    "            for i in range(self.kernelNum):\n",
    "                self.kernels[i] -= self.learningRate * resultBP['dK'][i]\n",
    "            \n",
    "            # if count % 100 == 0:\n",
    "            #     if count % 30000 == 0:\n",
    "            #         loss = self.loss(x_test,y_test)\n",
    "            #         test = self.testing(x_test,y_test)\n",
    "            #         print('Trained for {} times,'.format(count),'loss = {}, test = {}'.format(loss,test))\n",
    "            #         # loss_dict[str(count)]=loss\n",
    "            #         test_dict[str(count)]=test\n",
    "            #     else:\n",
    "            #         print('Trained for {} times,'.format(count))\n",
    "            count += 1\n",
    "\n",
    "        print(\"Training finished!\")\n",
    "        return lossDict, tesDict\n",
    "    \n",
    "model = CNN(batchSize=50, iterations=10, learningRate=0.05)\n",
    "model.train(imageTrain, labelTrain)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f2ec3a27b206c5c715624a547105f4453c6ed312d93e4b85e955c3b1a3db3dae"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
