{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the MNIST datasets - 60000 images for training and 10000 images for testing\n",
    "(imageTrain, labelTrain), (imageTest, labelTest) = tf.keras.datasets.mnist.load_data()\n",
    "# Splitting the training set into 2: 55000 images for training and 5000 images for validation\n",
    "# Raw 2d array\n",
    "imageTrainRaw = imageTrain[:55000]\n",
    "labelTrainRaw = labelTrain[:55000]\n",
    "imageValidRaw = imageTrain[55000:]\n",
    "labelValidRaw = labelTrain[55000:]\n",
    "# Processed 1d array\n",
    "imageTrainPro = np.reshape(imageTrainRaw, (55000, 784))\n",
    "imageTrainPro = preprocessing.normalize(imageTrainPro, norm=\"max\")\n",
    "labelTrainPro = np.zeros((55000, 10))\n",
    "for idx in range(55000):\n",
    "    labelTrainPro[idx][labelTrainRaw[idx]] = 1\n",
    "imageValidPro = np.reshape(imageValidRaw, (5000, 784))\n",
    "imageValidPro = preprocessing.normalize(imageValidPro, norm = \"max\")\n",
    "labelValidPro = np.zeros((5000, 10))\n",
    "for idx in range(5000):\n",
    "    labelValidPro[idx][labelValidRaw[idx]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing an image array\n",
    "def visualizeArr(idx):\n",
    "    imageArr = \"\"\n",
    "    for row in imageTrainRaw[idx]:\n",
    "        for col in row:\n",
    "            if(len(str(col)) == 1):\n",
    "                print(str(col) + \"   \", end =\" \")\n",
    "                imageArr += str(col) + \"   \"\n",
    "            elif(len(str(col)) == 2):\n",
    "                print(str(col) + \"  \", end =\" \")\n",
    "                imageArr += str(col) + \"  \"\n",
    "            else:\n",
    "                print(str(col) + \" \", end =\" \")\n",
    "                imageArr += str(col) + \" \"\n",
    "        print()\n",
    "        imageArr += \"\\n\"\n",
    "    with open(\"./test/imageArr.txt\", \"w\") as file:\n",
    "        file.write(imageArr)\n",
    "# Plotting an image\n",
    "def plotImage(idx):\n",
    "    plt.title(f\"Digit {labelTrainRaw[idx]}\")\n",
    "    plt.imshow(imageTrainRaw[idx], cmap='gray')\n",
    "    plt.savefig(\"./test/digit_grey.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up the neural network architecture and hyperparameters\n",
    "inputLayer = 784  # input layer (28x28 pixels)\n",
    "hiddenLayer1 = 512  # 1st hidden layer (14x14 pixel)\n",
    "hiddenLayer2 = 256  # 2nd hidden layer\n",
    "hiddenLayer3 = 128  # 3rd hidden layer\n",
    "outputLayer = 10  # output layer (0-9 digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] Loss: 3.0349079817602327\n",
      "[7] Loss: 2.889634000889487\n",
      "[11] Loss: 0.4820046257753735\n",
      "[34] Loss: 0.35304538736984353\n",
      "[131] Loss: 0.08547753349005642\n",
      "[234] Loss: 0.030342296315341338\n",
      "[999] Loss: 0.01676437018575291\n",
      "[16291] Loss: 0.015363532767866037\n",
      "[17982] Loss: 0.006971818526132726\n",
      "[33761] Loss: 0.0018920435871449901\n",
      "[45104] Loss: 0.0014984887651255745\n",
      "[51408] Loss: 0.0010386233673721527\n",
      "[61646] Loss: 0.0009357457795374462\n",
      "[71668] Loss: 0.000879162776316626\n",
      "[81719] Loss: 0.000559586164175905\n",
      "[88923] Loss: 0.0005181628668953624\n",
      "[103641] Loss: 0.00043907039294440153\n",
      "[107505] Loss: 0.00043229261407406544\n",
      "[108386] Loss: 0.00033063453888280134\n",
      "[108508] Loss: 0.0003252642281684447\n",
      "[120761] Loss: 0.0002968712175398353\n",
      "[122735] Loss: 0.0001541354352387583\n",
      "[127262] Loss: 0.0001343806461181574\n",
      "[136302] Loss: 9.966554411587004e-05\n",
      "[143821] Loss: 8.821208597221959e-05\n",
      "[179797] Loss: 5.80408445504169e-05\n",
      "[192150] Loss: 5.6110395316707534e-05\n",
      "[196926] Loss: 5.0317806893039824e-05\n",
      "[199115] Loss: 5.027532588735591e-05\n",
      "[220234] Loss: 3.4883401737430646e-05\n",
      "[231880] Loss: 3.432210559438502e-05\n",
      "[240075] Loss: 3.0197944486948028e-05\n",
      "[253213] Loss: 2.855322798917106e-05\n",
      "[260045] Loss: 9.503559676574757e-06\n",
      "[279679] Loss: 7.457847314404494e-06\n",
      "[310030] Loss: 5.892907658768574e-06\n",
      "[326561] Loss: 5.332493345423881e-06\n",
      "[525047] Loss: 4.933251118141408e-06\n",
      "[582032] Loss: 1.9165108038091004e-06\n",
      "[688832] Loss: 1.4455507514103622e-06\n",
      "[1038446] Loss: 1.2844582495601475e-06\n",
      "[1123975] Loss: 1.0065888529520975e-06\n",
      "[1218260] Loss: 9.81777684479114e-07\n",
      "0.9116\n"
     ]
    }
   ],
   "source": [
    "learningRate = np.float_power(10, -4)\n",
    "iterations = 300000\n",
    "\n",
    "theta = np.random.rand(784, 10)\n",
    "theta = np.reshape(theta, (10, 784))\n",
    "b = np.random.rand(10)\n",
    "\n",
    "# Implement softmax function using cross-entropy and SGD\n",
    "def softmax(y):\n",
    "    e = np.exp(y)\n",
    "    return e / sum(e)\n",
    "\n",
    "def fLoss(theta, b, idx): # Using cross-entropy and SGD\n",
    "    result = 0\n",
    "    x = imageTrainPro[idx]\n",
    "    yCal = theta.dot(x) + b\n",
    "    yCal = softmax(yCal)\n",
    "    yGiven = labelTrainPro[idx]\n",
    "    for c in range(10):\n",
    "        result += -(yGiven[c] * np.log(yCal[c]))\n",
    "    return result\n",
    "\n",
    "def dfLoss(theta, b, idx): # Using SGD\n",
    "    x = imageTrainPro[idx]\n",
    "    yCal = theta.dot(x) + b\n",
    "    yCal = softmax(yCal)\n",
    "    yGiven = labelTrainPro[idx]\n",
    "    result_w = (yCal - yGiven).reshape(10,1).dot(x.reshape(1, 784))\n",
    "    result_b =  yCal - yGiven\n",
    "    return (result_w, result_b)\n",
    "\n",
    "time = 0\n",
    "lossPrev = fLoss(theta, b, np.random.randint(0, 55000))      \n",
    "while True:\n",
    "    time += 1\n",
    "    idx = np.random.randint(0, 55000)\n",
    "    (dloss_w, dloss_b) = dfLoss(theta, b, idx)\n",
    "    theta = theta - learningRate * dloss_w\n",
    "    b = b - learningRate * dloss_b\n",
    "    loss = fLoss(theta, b, idx)\n",
    "    if(loss < lossPrev):\n",
    "        lossPrev = loss\n",
    "        thetaRes = theta\n",
    "        bRes = b\n",
    "        print(f\"[{time}] Loss: {loss}\")\n",
    "        if(loss < np.float_power(10, -6)):\n",
    "            break\n",
    "        \n",
    "count = 0\n",
    "for i in range(5000):\n",
    "    x_valid = imageValidPro[i]\n",
    "    y_valid = softmax(thetaRes.dot(x_valid) + bRes)\n",
    "    result = np.argmax(y_valid)\n",
    "    if(result == labelValidRaw[i]):\n",
    "        count += 1\n",
    "print((count / 5000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for i in range(5000):\n",
    "    x_valid = imageValidPro[i]\n",
    "    y_valid = softmax(theta.dot(x_valid) + b)\n",
    "    result = np.argmax(y_valid)\n",
    "    if(result == labelValidRaw[i]):\n",
    "        count += 1\n",
    "print((count / 5000))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f2ec3a27b206c5c715624a547105f4453c6ed312d93e4b85e955c3b1a3db3dae"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
