{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 578,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the MNIST datasets - 60000 images for training and 10000 images for testing\n",
    "(imageTrainRaw, labelTrainRaw), (imageTestRaw, labelTestRaw) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# Splitting the training set into 2: 55000 images for training and 5000 images for validation\n",
    "imageTestRaw = imageTestRaw[:]\n",
    "labelTestRaw = labelTestRaw[:]\n",
    "\n",
    "imageValidRaw = imageTrainRaw[55000:]\n",
    "labelValidRaw = labelTrainRaw[55000:]\n",
    "\n",
    "imageTrainRaw = imageTrainRaw[:55000]\n",
    "labelTrainRaw = labelTrainRaw[:55000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualizing data\n",
    "# Printing an array\n",
    "def printArr(idx):\n",
    "    to_write = \"\"\n",
    "    for i in range(28):\n",
    "        for j in range(28):\n",
    "            if(len(str(imageTrainRaw[idx][i][j])) == 1):\n",
    "                to_write += str(imageTrainRaw[idx][i][j]) + \"    \"\n",
    "            elif(len(str(imageTrainRaw[idx][i][j])) == 2):\n",
    "                to_write += str(imageTrainRaw[idx][i][j]) + \"   \"\n",
    "            else:\n",
    "                to_write += str(imageTrainRaw[idx][i][j]) + \"  \"\n",
    "        to_write += \"\\n\"\n",
    "    to_write += f\"\\nDigit: {labelTrainRaw[idx]}\"\n",
    "    with open(\"./test/imageArr.txt\", \"w\") as file:\n",
    "        file.write(to_write)\n",
    "        \n",
    "# Plotting an image\n",
    "def plotImage(idx):\n",
    "    pyplot.title(f\"Digit {labelTrainRaw[idx]}\")\n",
    "    pyplot.imshow(imageTrainRaw[idx], cmap='gray')\n",
    "    pyplot.savefig(\"./test/digitGrey.jpg\")\n",
    "\n",
    "idx = 7\n",
    "printArr(idx)\n",
    "plotImage(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing data (normalizing image arrays and 1-hot encoding label arrays)\n",
    "imageTest = imageTestRaw / 255\n",
    "labelTest = tf.keras.utils.to_categorical(labelTestRaw, num_classes=10)\n",
    "\n",
    "imageValid = imageValidRaw / 255\n",
    "labelValid = tf.keras.utils.to_categorical(labelValidRaw, num_classes=10)\n",
    "\n",
    "imageTrain = imageTrainRaw / 255\n",
    "labelTrain = tf.keras.utils.to_categorical(labelTrainRaw, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up the neural network layer dimension and hypermeters \n",
    "batchSize = 50      # Batch size to perform GD\n",
    "iter = 20000        # Number of iterations\n",
    "eta = 0.05          # Initial learning rate\n",
    "stride = 1          # Stride for convolution layer\n",
    "padding = 0         # Padding for convolution layer\n",
    "inputDim = 28       # Dimension of input layer = 28 x 28\n",
    "kernelNum = 1       # Number of kernels (filters)\n",
    "kernelDim = 3       # Dimension of kernel = 3 x 3\n",
    "featureDim = 26     # Dimension of feature map = inputDim + 2 * padding - kernelDim) / stride + 1 \n",
    "hiddenDim = 20      # Dimension of hidden layer = 20 x 20\n",
    "outputDim = 10      # Dimension of output layer = 10 x 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolution(x, k):\n",
    "    result = np.zeros((kernelNum, featureDim, featureDim))\n",
    "    \n",
    "    for n in range(kernelNum):\n",
    "        for i in range(featureDim):\n",
    "            for j in range(featureDim):\n",
    "                result[n, i, j] = np.sum(np.multiply(k[n], x[i : i + kernelDim, j : j + kernelDim]))\n",
    "    return result\n",
    "\n",
    "# ReLU activation for hidden layer\n",
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "# Softmax activation for output layer\n",
    "def softmax(x):\n",
    "    c = np.max(x, axis = 0, keepdims=True)\n",
    "    x -= c\n",
    "    e = np.exp(x)\n",
    "    return e / np.sum(e, axis = 0, keepdims=True)\n",
    "\n",
    "# Calculating loss value using cross entropy\n",
    "def lossCE(yCal, yLabel):\n",
    "    result = -np.sum(np.log(yCal) * yLabel)\n",
    "    return result\n",
    "\n",
    "def train(batchSize, iter, eta, filename):\n",
    "    # Initializing kernels, weights, biases and eta\n",
    "    k =  0.01 * np.random.rand(kernelNum, kernelDim, kernelDim)\n",
    "    w1 = 0.01 * np.random.rand(kernelNum * featureDim**2, hiddenDim**2)\n",
    "    b1 = 0.01 * np.random.rand(hiddenDim**2, 1)\n",
    "    w2 = 0.01 * np.random.rand(hiddenDim**2, outputDim)\n",
    "    b2 = 0.01 * np.random.rand(outputDim, 1)\n",
    "\n",
    "    \n",
    "    lossList = []\n",
    "    lossEpoch = 5\n",
    "    lossPrev = 1000\n",
    "    to_write = \"\"\n",
    "    \n",
    "    for n in range(iter + 1):\n",
    "        if(n % 100 == 0):\n",
    "            print(f\"[Iter {n}]\")\n",
    "            lossList.append(lossEpoch / batchSize)\n",
    "            \n",
    "        idxList = np.random.randint(low=0, high=55000, size=batchSize) \n",
    "        lossEpoch = 0\n",
    "        \n",
    "        for idx in idxList:\n",
    "            # Feedforward\n",
    "            x = imageTrain[idx]\n",
    "            v = convolution(x, k).reshape(kernelNum * featureDim**2, 1)\n",
    "            z1 = np.dot(w1.T, v) + b1\n",
    "            a1 = relu(z1)\n",
    "            z2 = np.dot(w2.T, a1) + b2\n",
    "            a2 = softmax(z2)\n",
    "        \n",
    "            yCal = a2\n",
    "            yLabel = labelTrain[idx].reshape(10, 1)\n",
    "            loss = lossCE(yCal, yLabel)\n",
    "            lossEpoch += loss\n",
    "            if(loss < lossPrev):\n",
    "                lossPrev = loss\n",
    "                kRes = k\n",
    "                w1Res = w1\n",
    "                b1Res = b1\n",
    "                w2Res = w2\n",
    "                b2Res = b2\n",
    "                print(f\"[Iter {n}] Loss: {loss}\")\n",
    "                to_write += f\"[Iter {n}] Loss: {loss}\\n\"\n",
    "                \n",
    "            # Backpropagation\n",
    "            e2 = yCal - yLabel # gradient of softmax using cross entropy\n",
    "            dw2 = np.dot(a1, e2.T)\n",
    "            db2 = e2\n",
    "            e1 = np.dot(w2, e2)\n",
    "            e1[z1 <= 0] = 0 # gradient of ReLU\n",
    "            dw1 = np.dot(v, e1.T)\n",
    "            db1 = e1\n",
    "\n",
    "            # Updating weights and biases\n",
    "            w1 += -eta * dw1\n",
    "            b1 += -eta * db1\n",
    "            w2 += -eta * dw2\n",
    "            b2 += -eta * db2\n",
    "    \n",
    "    with open(f\"./test/{filename}.txt\", \"w\") as file:\n",
    "        file.write(to_write)\n",
    "        \n",
    "    return (kRes, w1Res, b1Res, w2Res, b2Res, lossList)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkValid(kRes, w1Res, b1Res, w2Res, b2Res):\n",
    "    count = 0\n",
    "    for idx in range(5000):\n",
    "        if(idx % 100 == 0 or idx == 4999):\n",
    "            print(f\"Image: {idx}\")\n",
    "        x = imageValid[idx]\n",
    "        v = convolution(x, kRes).reshape(1, kernelNum * featureDim**2)\n",
    "        z1 = np.dot(w1Res.T, v.T) + b1Res\n",
    "        a1 = relu(z1)\n",
    "        z2 = np.dot(w2Res.T, a1) + b2Res\n",
    "        a2 = softmax(z2)\n",
    "        yCal = a2\n",
    "        yLabel = labelValid[idx].reshape(10, 1)\n",
    "        prediction = np.argmax(yCal, axis=0)\n",
    "        answer = np.argmax(yLabel, axis=0)\n",
    "        if(prediction == answer):\n",
    "            count += 1\n",
    "    return count / 5000\n",
    "\n",
    "def checkTest(kRes, w1Res, b1Res, w2Res, b2Res):\n",
    "    count = 0\n",
    "    for idx in range(10000):\n",
    "        if(idx % 100 == 0 or idx == 9999):\n",
    "            print(f\"Image: {idx}\")\n",
    "        x = imageTest[idx]\n",
    "        v = convolution(x, kRes).reshape(1, kernelNum * featureDim**2)\n",
    "        z1 = np.dot(w1Res.T, v.T) + b1Res\n",
    "        a1 = relu(z1)\n",
    "        z2 = np.dot(w2Res.T, a1) + b2Res\n",
    "        a2 = softmax(z2)\n",
    "        yCal = a2\n",
    "        yLabel = labelTest[idx].reshape(10, 1)\n",
    "        prediction = np.argmax(yCal, axis=0)\n",
    "        answer = np.argmax(yLabel, axis=0)\n",
    "        if(prediction == answer):\n",
    "            count += 1\n",
    "    return count / 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iter 0]\n",
      "[Iter 0] Loss: 2.3003172134770646\n",
      "[Iter 2] Loss: 2.235486843961148\n",
      "[Iter 9] Loss: 2.204023008659503\n",
      "[Iter 18] Loss: 2.194129845556492\n",
      "[Iter 23] Loss: 2.17634025632191\n",
      "[Iter 25] Loss: 2.0989857148774353\n",
      "[Iter 30] Loss: 2.047101725618289\n",
      "[Iter 56] Loss: 2.0286020843703847\n",
      "[Iter 60] Loss: 1.983444598330637\n",
      "[Iter 66] Loss: 1.972960340551427\n",
      "[Iter 73] Loss: 1.9601306475089664\n",
      "[Iter 100]\n",
      "[Iter 200]\n",
      "[Iter 300]\n",
      "[Iter 400]\n",
      "[Iter 444] Loss: 1.960087828829347\n",
      "[Iter 500]\n",
      "[Iter 524] Loss: 1.9224703806861614\n",
      "[Iter 600]\n",
      "[Iter 700]\n",
      "[Iter 800]\n",
      "[Iter 875] Loss: 1.8246619909162043\n",
      "[Iter 883] Loss: 1.693435346825172\n",
      "[Iter 900]\n",
      "[Iter 1000]\n",
      "[Iter 1040] Loss: 1.5943486336676038\n",
      "[Iter 1094] Loss: 1.4042935873495217\n",
      "[Iter 1100]\n",
      "[Iter 1200]\n",
      "[Iter 1240] Loss: 1.26596782153989\n",
      "[Iter 1255] Loss: 1.1495173536766077\n",
      "[Iter 1300]\n",
      "[Iter 1369] Loss: 0.7701230892563117\n",
      "[Iter 1400]\n",
      "[Iter 1500]\n",
      "[Iter 1531] Loss: 0.6469037277098613\n",
      "[Iter 1600]\n",
      "[Iter 1700]\n",
      "[Iter 1709] Loss: 0.29379415756000415\n",
      "[Iter 1800]\n",
      "[Iter 1900]\n",
      "[Iter 2000]\n",
      "[Iter 2100]\n",
      "[Iter 2196] Loss: 0.1477808735370925\n",
      "[Iter 2200]\n",
      "[Iter 2300]\n",
      "[Iter 2400]\n",
      "[Iter 2500]\n",
      "[Iter 2600]\n",
      "[Iter 2700]\n",
      "[Iter 2800]\n",
      "[Iter 2900]\n",
      "[Iter 3000]\n",
      "[Iter 3100]\n",
      "[Iter 3147] Loss: 0.12207196652792915\n",
      "[Iter 3200]\n",
      "[Iter 3250] Loss: 0.10831014050922856\n",
      "[Iter 3274] Loss: 0.09666433527486155\n",
      "[Iter 3300]\n",
      "[Iter 3323] Loss: 0.047191187263968724\n",
      "[Iter 3400]\n",
      "[Iter 3500]\n",
      "[Iter 3600]\n",
      "[Iter 3700]\n",
      "[Iter 3800]\n",
      "[Iter 3900]\n",
      "[Iter 4000]\n",
      "[Iter 4100]\n",
      "[Iter 4200]\n",
      "[Iter 4300]\n",
      "[Iter 4400]\n",
      "[Iter 4483] Loss: 0.023138066129355914\n",
      "[Iter 4500]\n",
      "[Iter 4600]\n",
      "[Iter 4700]\n",
      "[Iter 4800]\n",
      "[Iter 4900]\n",
      "[Iter 5000]\n",
      "[Iter 5100]\n",
      "[Iter 5200]\n",
      "[Iter 5300]\n",
      "[Iter 5400]\n",
      "[Iter 5500]\n",
      "[Iter 5600]\n",
      "[Iter 5700]\n",
      "[Iter 5800]\n",
      "[Iter 5882] Loss: 0.01875544688222341\n",
      "[Iter 5900]\n",
      "[Iter 6000]\n",
      "[Iter 6100]\n",
      "[Iter 6200]\n",
      "[Iter 6300]\n",
      "[Iter 6382] Loss: 0.01505997821378826\n",
      "[Iter 6400]\n",
      "[Iter 6425] Loss: 0.011983300956444051\n",
      "[Iter 6500]\n",
      "[Iter 6600]\n",
      "[Iter 6646] Loss: 0.00570845458681953\n",
      "[Iter 6700]\n",
      "[Iter 6800]\n",
      "[Iter 6900]\n",
      "[Iter 6905] Loss: 0.0028749644574144317\n",
      "[Iter 7000]\n",
      "[Iter 7100]\n",
      "[Iter 7200]\n",
      "[Iter 7226] Loss: 0.0014433079932293848\n",
      "[Iter 7300]\n",
      "[Iter 7400]\n",
      "[Iter 7500]\n",
      "[Iter 7600]\n",
      "[Iter 7700]\n",
      "[Iter 7800]\n",
      "[Iter 7900]\n",
      "[Iter 8000]\n",
      "[Iter 8100]\n",
      "[Iter 8200]\n",
      "[Iter 8300]\n",
      "[Iter 8400]\n",
      "[Iter 8500]\n",
      "[Iter 8600]\n",
      "[Iter 8700]\n",
      "[Iter 8800]\n",
      "[Iter 8900]\n",
      "[Iter 9000]\n",
      "[Iter 9037] Loss: 0.0005907907634141069\n",
      "[Iter 9100]\n",
      "[Iter 9200]\n",
      "[Iter 9300]\n",
      "[Iter 9400]\n",
      "[Iter 9500]\n",
      "[Iter 9600]\n",
      "[Iter 9700]\n",
      "[Iter 9800]\n",
      "[Iter 9900]\n",
      "[Iter 10000]\n",
      "[Iter 10100]\n",
      "[Iter 10200]\n",
      "[Iter 10300]\n",
      "[Iter 10400]\n",
      "[Iter 10500]\n",
      "[Iter 10600]\n",
      "[Iter 10700]\n",
      "[Iter 10705] Loss: 0.00039803417719124916\n",
      "[Iter 10800]\n",
      "[Iter 10900]\n",
      "[Iter 11000]\n",
      "[Iter 11100]\n",
      "[Iter 11200]\n",
      "[Iter 11229] Loss: 0.00014317110472507338\n",
      "[Iter 11300]\n",
      "[Iter 11400]\n",
      "[Iter 11500]\n",
      "[Iter 11600]\n",
      "[Iter 11700]\n",
      "[Iter 11800]\n",
      "[Iter 11900]\n",
      "[Iter 12000]\n",
      "[Iter 12100]\n",
      "[Iter 12200]\n",
      "[Iter 12300]\n",
      "[Iter 12400]\n",
      "[Iter 12500]\n",
      "[Iter 12600]\n",
      "[Iter 12700]\n",
      "[Iter 12800]\n",
      "[Iter 12900]\n",
      "[Iter 13000]\n",
      "[Iter 13040] Loss: 0.00011154561526815177\n",
      "[Iter 13100]\n",
      "[Iter 13200]\n",
      "[Iter 13300]\n",
      "[Iter 13400]\n",
      "[Iter 13500]\n",
      "[Iter 13600]\n",
      "[Iter 13700]\n",
      "[Iter 13725] Loss: 9.613956123403327e-05\n",
      "[Iter 13800]\n",
      "[Iter 13900]\n",
      "[Iter 14000]\n",
      "[Iter 14100]\n",
      "[Iter 14200]\n",
      "[Iter 14300]\n",
      "[Iter 14400]\n",
      "[Iter 14465] Loss: 4.9775957984880636e-05\n",
      "[Iter 14500]\n",
      "[Iter 14600]\n",
      "[Iter 14700]\n",
      "[Iter 14800]\n",
      "[Iter 14900]\n",
      "[Iter 15000]\n",
      "[Iter 15100]\n",
      "[Iter 15200]\n",
      "[Iter 15300]\n",
      "[Iter 15400]\n",
      "[Iter 15500]\n",
      "[Iter 15600]\n",
      "[Iter 15700]\n",
      "[Iter 15800]\n",
      "[Iter 15900]\n",
      "[Iter 15980] Loss: 2.719928734077837e-05\n",
      "[Iter 16000]\n",
      "[Iter 16100]\n",
      "[Iter 16200]\n",
      "[Iter 16300]\n",
      "[Iter 16400]\n",
      "[Iter 16500]\n",
      "[Iter 16600]\n",
      "[Iter 16700]\n",
      "[Iter 16800]\n",
      "[Iter 16900]\n",
      "[Iter 16938] Loss: 1.812576881215189e-05\n",
      "[Iter 17000]\n",
      "[Iter 17100]\n",
      "[Iter 17200]\n",
      "[Iter 17300]\n",
      "[Iter 17400]\n",
      "[Iter 17500]\n",
      "[Iter 17600]\n",
      "[Iter 17700]\n",
      "[Iter 17800]\n",
      "[Iter 17900]\n",
      "[Iter 18000]\n",
      "[Iter 18100]\n",
      "[Iter 18200]\n",
      "[Iter 18300]\n",
      "[Iter 18400]\n",
      "[Iter 18500]\n",
      "[Iter 18600]\n",
      "[Iter 18700]\n",
      "[Iter 18800]\n",
      "[Iter 18900]\n",
      "[Iter 19000]\n",
      "[Iter 19100]\n",
      "[Iter 19158] Loss: 1.4195142058837062e-05\n",
      "[Iter 19200]\n",
      "[Iter 19300]\n",
      "[Iter 19400]\n",
      "[Iter 19500]\n",
      "[Iter 19600]\n",
      "[Iter 19700]\n",
      "[Iter 19800]\n",
      "[Iter 19900]\n",
      "[Iter 20000]\n",
      "[Iter 20100]\n",
      "[Iter 20200]\n",
      "[Iter 20300]\n",
      "[Iter 20400]\n",
      "[Iter 20500]\n",
      "[Iter 20600]\n",
      "[Iter 20700]\n",
      "[Iter 20800]\n",
      "[Iter 20900]\n",
      "[Iter 21000]\n",
      "[Iter 21100]\n",
      "[Iter 21200]\n",
      "[Iter 21300]\n",
      "[Iter 21400]\n",
      "[Iter 21500]\n",
      "[Iter 21600]\n",
      "[Iter 21700]\n",
      "[Iter 21800]\n",
      "[Iter 21900]\n",
      "[Iter 22000]\n",
      "[Iter 22100]\n",
      "[Iter 22200]\n",
      "[Iter 22300]\n",
      "[Iter 22400]\n",
      "[Iter 22500]\n",
      "[Iter 22600]\n",
      "[Iter 22700]\n",
      "[Iter 22800]\n",
      "[Iter 22900]\n",
      "[Iter 23000]\n",
      "[Iter 23100]\n",
      "[Iter 23200]\n",
      "[Iter 23300]\n",
      "[Iter 23400]\n",
      "[Iter 23500]\n",
      "[Iter 23600]\n",
      "[Iter 23700]\n",
      "[Iter 23800]\n",
      "[Iter 23900]\n",
      "[Iter 24000]\n",
      "[Iter 24100]\n",
      "[Iter 24200]\n",
      "[Iter 24300]\n",
      "[Iter 24400]\n",
      "[Iter 24500]\n",
      "[Iter 24600]\n",
      "[Iter 24700]\n",
      "[Iter 24800]\n",
      "[Iter 24900]\n",
      "[Iter 25000]\n",
      "[Iter 25100]\n",
      "[Iter 25200]\n",
      "[Iter 25300]\n",
      "[Iter 25343] Loss: 9.972696738457376e-07\n",
      "[Iter 25400]\n",
      "[Iter 25500]\n",
      "[Iter 25600]\n",
      "[Iter 25700]\n",
      "[Iter 25800]\n",
      "[Iter 25900]\n",
      "[Iter 26000]\n",
      "[Iter 26100]\n",
      "[Iter 26200]\n",
      "[Iter 26300]\n",
      "[Iter 26400]\n",
      "[Iter 26500]\n",
      "[Iter 26600]\n",
      "[Iter 26700]\n",
      "[Iter 26800]\n",
      "[Iter 26900]\n",
      "[Iter 27000]\n",
      "[Iter 27100]\n",
      "[Iter 27200]\n",
      "[Iter 27300]\n",
      "[Iter 27400]\n",
      "[Iter 27500]\n",
      "[Iter 27600]\n",
      "[Iter 27700]\n",
      "[Iter 27800]\n",
      "[Iter 27900]\n",
      "[Iter 28000]\n",
      "[Iter 28100]\n",
      "[Iter 28200]\n",
      "[Iter 28300]\n",
      "[Iter 28400]\n",
      "[Iter 28500]\n",
      "[Iter 28600]\n",
      "[Iter 28700]\n",
      "[Iter 28800]\n",
      "[Iter 28900]\n",
      "[Iter 29000]\n",
      "[Iter 29100]\n",
      "[Iter 29200]\n",
      "[Iter 29300]\n",
      "[Iter 29400]\n",
      "[Iter 29500]\n",
      "[Iter 29600]\n",
      "[Iter 29700]\n",
      "[Iter 29800]\n",
      "[Iter 29900]\n",
      "[Iter 30000]\n",
      "[Iter 30100]\n",
      "[Iter 30200]\n",
      "[Iter 30300]\n",
      "[Iter 30400]\n",
      "[Iter 30500]\n",
      "[Iter 30600]\n",
      "[Iter 30700]\n",
      "[Iter 30800]\n",
      "[Iter 30900]\n",
      "[Iter 31000]\n",
      "[Iter 31100]\n",
      "[Iter 31200]\n",
      "[Iter 31300]\n",
      "[Iter 31400]\n",
      "[Iter 31500]\n",
      "[Iter 31600]\n",
      "[Iter 31700]\n",
      "[Iter 31800]\n",
      "[Iter 31900]\n",
      "[Iter 32000]\n",
      "[Iter 32100]\n",
      "[Iter 32200]\n",
      "[Iter 32300]\n",
      "[Iter 32400]\n",
      "[Iter 32500]\n",
      "[Iter 32600]\n",
      "[Iter 32700]\n",
      "[Iter 32800]\n",
      "[Iter 32900]\n",
      "[Iter 33000]\n",
      "[Iter 33100]\n",
      "[Iter 33200]\n",
      "[Iter 33300]\n",
      "[Iter 33400]\n",
      "[Iter 33500]\n",
      "[Iter 33600]\n",
      "[Iter 33700]\n",
      "[Iter 33800]\n",
      "[Iter 33900]\n",
      "[Iter 34000]\n",
      "[Iter 34100]\n",
      "[Iter 34200]\n",
      "[Iter 34300]\n",
      "[Iter 34400]\n",
      "[Iter 34500]\n",
      "[Iter 34600]\n",
      "[Iter 34700]\n",
      "[Iter 34800]\n",
      "[Iter 34900]\n",
      "[Iter 35000]\n",
      "[Iter 35100]\n",
      "[Iter 35200]\n",
      "[Iter 35300]\n",
      "[Iter 35400]\n",
      "[Iter 35500]\n",
      "[Iter 35600]\n",
      "[Iter 35700]\n",
      "[Iter 35800]\n",
      "[Iter 35900]\n",
      "[Iter 36000]\n",
      "[Iter 36023] Loss: 3.8893976153953777e-07\n",
      "[Iter 36100]\n",
      "[Iter 36200]\n",
      "[Iter 36300]\n",
      "[Iter 36400]\n",
      "[Iter 36500]\n",
      "[Iter 36600]\n",
      "[Iter 36700]\n",
      "[Iter 36800]\n",
      "[Iter 36900]\n",
      "[Iter 37000]\n",
      "[Iter 37100]\n",
      "[Iter 37200]\n",
      "[Iter 37300]\n",
      "[Iter 37400]\n",
      "[Iter 37500]\n",
      "[Iter 37600]\n",
      "[Iter 37700]\n",
      "[Iter 37800]\n",
      "[Iter 37900]\n",
      "[Iter 38000]\n",
      "[Iter 38100]\n",
      "[Iter 38200]\n",
      "[Iter 38300]\n",
      "[Iter 38400]\n",
      "[Iter 38500]\n",
      "[Iter 38600]\n",
      "[Iter 38700]\n",
      "[Iter 38800]\n",
      "[Iter 38900]\n",
      "[Iter 39000]\n",
      "[Iter 39100]\n",
      "[Iter 39200]\n",
      "[Iter 39300]\n",
      "[Iter 39400]\n",
      "[Iter 39500]\n",
      "[Iter 39600]\n",
      "[Iter 39700]\n",
      "[Iter 39800]\n",
      "[Iter 39900]\n",
      "[Iter 40000]\n",
      "[Iter 40100]\n",
      "[Iter 40200]\n",
      "[Iter 40300]\n",
      "[Iter 40400]\n",
      "[Iter 40500]\n",
      "[Iter 40600]\n",
      "[Iter 40700]\n",
      "[Iter 40800]\n",
      "[Iter 40900]\n",
      "[Iter 41000]\n",
      "[Iter 41100]\n",
      "[Iter 41200]\n",
      "[Iter 41300]\n",
      "[Iter 41400]\n",
      "[Iter 41500]\n",
      "[Iter 41600]\n",
      "[Iter 41700]\n",
      "[Iter 41800]\n",
      "[Iter 41900]\n",
      "[Iter 42000]\n",
      "[Iter 42100]\n",
      "[Iter 42200]\n",
      "[Iter 42300]\n",
      "[Iter 42400]\n",
      "[Iter 42500]\n",
      "[Iter 42600]\n",
      "[Iter 42700]\n",
      "[Iter 42800]\n",
      "[Iter 42900]\n",
      "[Iter 43000]\n",
      "[Iter 43100]\n",
      "[Iter 43200]\n",
      "[Iter 43300]\n",
      "[Iter 43400]\n",
      "[Iter 43500]\n",
      "[Iter 43600]\n",
      "[Iter 43700]\n",
      "[Iter 43800]\n",
      "[Iter 43900]\n",
      "[Iter 44000]\n",
      "[Iter 44100]\n",
      "[Iter 44200]\n",
      "[Iter 44300]\n",
      "[Iter 44400]\n",
      "[Iter 44500]\n",
      "[Iter 44600]\n",
      "[Iter 44700]\n",
      "[Iter 44800]\n",
      "[Iter 44900]\n",
      "[Iter 45000]\n",
      "[Iter 45100]\n",
      "[Iter 45200]\n",
      "[Iter 45300]\n",
      "[Iter 45400]\n",
      "[Iter 45500]\n",
      "[Iter 45600]\n",
      "[Iter 45700]\n",
      "[Iter 45800]\n",
      "[Iter 45900]\n",
      "[Iter 46000]\n",
      "[Iter 46100]\n",
      "[Iter 46200]\n",
      "[Iter 46300]\n",
      "[Iter 46400]\n",
      "[Iter 46500]\n",
      "[Iter 46600]\n",
      "[Iter 46700]\n",
      "[Iter 46800]\n",
      "[Iter 46900]\n",
      "[Iter 47000]\n",
      "[Iter 47100]\n",
      "[Iter 47200]\n",
      "[Iter 47300]\n",
      "[Iter 47400]\n",
      "[Iter 47500]\n",
      "[Iter 47600]\n",
      "[Iter 47700]\n",
      "[Iter 47800]\n",
      "[Iter 47900]\n",
      "[Iter 48000]\n",
      "[Iter 48100]\n",
      "[Iter 48200]\n",
      "[Iter 48300]\n",
      "[Iter 48400]\n",
      "[Iter 48500]\n",
      "[Iter 48600]\n",
      "[Iter 48700]\n",
      "[Iter 48800]\n",
      "[Iter 48900]\n",
      "[Iter 49000]\n",
      "[Iter 49100]\n",
      "[Iter 49200]\n",
      "[Iter 49300]\n",
      "[Iter 49400]\n",
      "[Iter 49500]\n",
      "[Iter 49600]\n",
      "[Iter 49700]\n",
      "[Iter 49800]\n",
      "[Iter 49900]\n",
      "[Iter 50000]\n",
      "[Iter 50100]\n",
      "[Iter 50200]\n",
      "[Iter 50300]\n",
      "[Iter 50400]\n",
      "[Iter 50500]\n",
      "[Iter 50600]\n",
      "[Iter 50700]\n",
      "[Iter 50800]\n",
      "[Iter 50900]\n",
      "[Iter 51000]\n",
      "[Iter 51100]\n",
      "[Iter 51200]\n",
      "[Iter 51300]\n",
      "[Iter 51400]\n",
      "[Iter 51500]\n",
      "[Iter 51600]\n",
      "[Iter 51700]\n",
      "[Iter 51800]\n",
      "[Iter 51900]\n",
      "[Iter 52000]\n",
      "[Iter 52013] Loss: 3.177772112987812e-07\n",
      "[Iter 52100]\n",
      "[Iter 52200]\n",
      "[Iter 52300]\n",
      "[Iter 52400]\n",
      "[Iter 52500]\n",
      "[Iter 52600]\n",
      "[Iter 52700]\n",
      "[Iter 52800]\n",
      "[Iter 52900]\n",
      "[Iter 53000]\n",
      "[Iter 53100]\n",
      "[Iter 53200]\n",
      "[Iter 53300]\n",
      "[Iter 53400]\n",
      "[Iter 53500]\n",
      "[Iter 53600]\n",
      "[Iter 53700]\n",
      "[Iter 53756] Loss: 3.845342951384286e-08\n",
      "[Iter 53800]\n",
      "[Iter 53900]\n",
      "[Iter 54000]\n",
      "[Iter 54100]\n",
      "[Iter 54200]\n",
      "[Iter 54300]\n",
      "[Iter 54400]\n",
      "[Iter 54500]\n",
      "[Iter 54600]\n",
      "[Iter 54700]\n",
      "[Iter 54800]\n",
      "[Iter 54900]\n",
      "[Iter 55000]\n",
      "[Iter 55100]\n",
      "[Iter 55200]\n",
      "[Iter 55300]\n",
      "[Iter 55400]\n",
      "[Iter 55500]\n",
      "[Iter 55600]\n",
      "[Iter 55700]\n",
      "[Iter 55800]\n",
      "[Iter 55900]\n",
      "[Iter 56000]\n",
      "[Iter 56100]\n",
      "[Iter 56200]\n",
      "[Iter 56300]\n",
      "[Iter 56400]\n",
      "[Iter 56500]\n",
      "[Iter 56600]\n",
      "[Iter 56700]\n",
      "[Iter 56800]\n",
      "[Iter 56900]\n",
      "[Iter 57000]\n",
      "[Iter 57100]\n",
      "[Iter 57200]\n",
      "[Iter 57300]\n",
      "[Iter 57400]\n",
      "[Iter 57500]\n",
      "[Iter 57600]\n",
      "[Iter 57700]\n",
      "[Iter 57800]\n",
      "[Iter 57900]\n",
      "[Iter 58000]\n",
      "[Iter 58100]\n",
      "[Iter 58200]\n",
      "[Iter 58300]\n",
      "[Iter 58400]\n",
      "[Iter 58500]\n",
      "[Iter 58600]\n",
      "[Iter 58700]\n",
      "[Iter 58800]\n",
      "[Iter 58900]\n",
      "[Iter 59000]\n",
      "[Iter 59100]\n",
      "[Iter 59200]\n",
      "[Iter 59300]\n",
      "[Iter 59400]\n",
      "[Iter 59500]\n",
      "[Iter 59600]\n",
      "[Iter 59700]\n",
      "[Iter 59800]\n",
      "[Iter 59900]\n",
      "[Iter 60000]\n",
      "[Iter 60100]\n",
      "[Iter 60200]\n",
      "[Iter 60300]\n",
      "[Iter 60400]\n",
      "[Iter 60500]\n",
      "[Iter 60600]\n",
      "[Iter 60700]\n",
      "[Iter 60800]\n",
      "[Iter 60900]\n",
      "[Iter 61000]\n",
      "[Iter 61100]\n",
      "[Iter 61200]\n",
      "[Iter 61300]\n",
      "[Iter 61400]\n",
      "[Iter 61500]\n",
      "[Iter 61600]\n",
      "[Iter 61700]\n",
      "[Iter 61800]\n",
      "[Iter 61900]\n",
      "[Iter 62000]\n",
      "[Iter 62100]\n",
      "[Iter 62200]\n",
      "[Iter 62300]\n",
      "[Iter 62400]\n",
      "[Iter 62500]\n",
      "[Iter 62600]\n",
      "[Iter 62700]\n",
      "[Iter 62800]\n",
      "[Iter 62900]\n",
      "[Iter 63000]\n",
      "[Iter 63100]\n",
      "[Iter 63200]\n",
      "[Iter 63300]\n",
      "[Iter 63400]\n",
      "[Iter 63500]\n",
      "[Iter 63600]\n",
      "[Iter 63700]\n",
      "[Iter 63800]\n",
      "[Iter 63900]\n",
      "[Iter 64000]\n",
      "[Iter 64100]\n",
      "[Iter 64200]\n",
      "[Iter 64300]\n",
      "[Iter 64400]\n",
      "[Iter 64500]\n",
      "[Iter 64600]\n",
      "[Iter 64700]\n",
      "[Iter 64800]\n",
      "[Iter 64900]\n",
      "[Iter 65000]\n",
      "[Iter 65100]\n",
      "[Iter 65200]\n",
      "[Iter 65300]\n",
      "[Iter 65400]\n",
      "[Iter 65500]\n",
      "[Iter 65600]\n",
      "[Iter 65700]\n",
      "[Iter 65800]\n",
      "[Iter 65900]\n",
      "[Iter 66000]\n",
      "[Iter 66100]\n",
      "[Iter 66122] Loss: 1.030696988629051e-08\n",
      "[Iter 66200]\n",
      "[Iter 66300]\n",
      "[Iter 66400]\n",
      "[Iter 66500]\n",
      "[Iter 66600]\n",
      "[Iter 66700]\n",
      "[Iter 66800]\n",
      "[Iter 66900]\n",
      "[Iter 67000]\n",
      "[Iter 67100]\n",
      "[Iter 67200]\n",
      "[Iter 67300]\n",
      "[Iter 67400]\n",
      "[Iter 67500]\n",
      "[Iter 67600]\n",
      "[Iter 67700]\n",
      "[Iter 67800]\n",
      "[Iter 67900]\n",
      "[Iter 68000]\n",
      "[Iter 68100]\n",
      "[Iter 68200]\n",
      "[Iter 68300]\n",
      "[Iter 68400]\n",
      "[Iter 68500]\n",
      "[Iter 68600]\n",
      "[Iter 68700]\n",
      "[Iter 68800]\n",
      "[Iter 68900]\n",
      "[Iter 69000]\n",
      "[Iter 69100]\n",
      "[Iter 69200]\n",
      "[Iter 69300]\n",
      "[Iter 69400]\n",
      "[Iter 69500]\n",
      "[Iter 69600]\n",
      "[Iter 69700]\n",
      "[Iter 69800]\n",
      "[Iter 69900]\n",
      "[Iter 70000]\n",
      "[Iter 70100]\n",
      "[Iter 70200]\n",
      "[Iter 70300]\n",
      "[Iter 70400]\n",
      "[Iter 70500]\n",
      "[Iter 70600]\n",
      "[Iter 70700]\n",
      "[Iter 70800]\n",
      "[Iter 70900]\n",
      "[Iter 71000]\n",
      "[Iter 71100]\n",
      "[Iter 71129] Loss: 8.164176005245127e-10\n",
      "[Iter 71200]\n",
      "[Iter 71300]\n",
      "[Iter 71400]\n",
      "[Iter 71500]\n",
      "[Iter 71600]\n",
      "[Iter 71700]\n",
      "[Iter 71800]\n",
      "[Iter 71900]\n",
      "[Iter 72000]\n",
      "[Iter 72100]\n",
      "[Iter 72200]\n",
      "[Iter 72300]\n",
      "[Iter 72400]\n",
      "[Iter 72500]\n",
      "[Iter 72600]\n",
      "[Iter 72700]\n",
      "[Iter 72800]\n",
      "[Iter 72900]\n",
      "[Iter 73000]\n",
      "[Iter 73100]\n",
      "[Iter 73200]\n",
      "[Iter 73300]\n",
      "[Iter 73400]\n",
      "[Iter 73500]\n",
      "[Iter 73600]\n",
      "[Iter 73700]\n",
      "[Iter 73800]\n",
      "[Iter 73900]\n",
      "[Iter 74000]\n",
      "[Iter 74100]\n",
      "[Iter 74200]\n",
      "[Iter 74300]\n",
      "[Iter 74400]\n",
      "[Iter 74500]\n",
      "[Iter 74600]\n",
      "[Iter 74700]\n",
      "[Iter 74800]\n",
      "[Iter 74900]\n",
      "[Iter 75000]\n",
      "[Iter 75100]\n",
      "[Iter 75200]\n",
      "[Iter 75300]\n",
      "[Iter 75400]\n",
      "[Iter 75500]\n",
      "[Iter 75600]\n",
      "[Iter 75700]\n",
      "[Iter 75800]\n",
      "[Iter 75900]\n",
      "[Iter 76000]\n",
      "[Iter 76100]\n",
      "[Iter 76200]\n",
      "[Iter 76300]\n",
      "[Iter 76400]\n",
      "[Iter 76500]\n",
      "[Iter 76600]\n",
      "[Iter 76700]\n",
      "[Iter 76800]\n",
      "[Iter 76900]\n",
      "[Iter 77000]\n",
      "[Iter 77100]\n",
      "[Iter 77200]\n",
      "[Iter 77300]\n",
      "[Iter 77400]\n",
      "[Iter 77500]\n",
      "[Iter 77600]\n",
      "[Iter 77700]\n",
      "[Iter 77800]\n",
      "[Iter 77900]\n",
      "[Iter 78000]\n",
      "[Iter 78100]\n",
      "[Iter 78200]\n",
      "[Iter 78300]\n",
      "[Iter 78400]\n",
      "[Iter 78500]\n",
      "[Iter 78600]\n",
      "[Iter 78700]\n",
      "[Iter 78800]\n",
      "[Iter 78900]\n",
      "[Iter 79000]\n",
      "[Iter 79100]\n",
      "[Iter 79200]\n",
      "[Iter 79300]\n",
      "[Iter 79400]\n",
      "[Iter 79500]\n",
      "[Iter 79600]\n",
      "[Iter 79700]\n",
      "[Iter 79800]\n",
      "[Iter 79900]\n",
      "[Iter 80000]\n",
      "[Iter 80100]\n",
      "[Iter 80200]\n",
      "[Iter 80300]\n",
      "[Iter 80400]\n",
      "[Iter 80500]\n",
      "[Iter 80600]\n",
      "[Iter 80700]\n",
      "[Iter 80800]\n",
      "[Iter 80900]\n",
      "[Iter 81000]\n",
      "[Iter 81100]\n",
      "[Iter 81200]\n",
      "[Iter 81300]\n",
      "[Iter 81400]\n",
      "[Iter 81500]\n",
      "[Iter 81600]\n",
      "[Iter 81700]\n",
      "[Iter 81800]\n",
      "[Iter 81900]\n",
      "[Iter 82000]\n",
      "[Iter 82100]\n",
      "[Iter 82200]\n",
      "[Iter 82300]\n",
      "[Iter 82400]\n",
      "[Iter 82500]\n",
      "[Iter 82600]\n",
      "[Iter 82700]\n",
      "[Iter 82800]\n",
      "[Iter 82900]\n",
      "[Iter 83000]\n",
      "[Iter 83100]\n",
      "[Iter 83200]\n",
      "[Iter 83300]\n",
      "[Iter 83400]\n",
      "[Iter 83500]\n",
      "[Iter 83600]\n",
      "[Iter 83700]\n",
      "[Iter 83800]\n",
      "[Iter 83900]\n",
      "[Iter 84000]\n",
      "[Iter 84100]\n",
      "[Iter 84200]\n",
      "[Iter 84300]\n",
      "[Iter 84400]\n",
      "[Iter 84500]\n",
      "[Iter 84600]\n",
      "[Iter 84700]\n",
      "[Iter 84800]\n",
      "[Iter 84900]\n",
      "[Iter 85000]\n",
      "[Iter 85100]\n",
      "[Iter 85200]\n",
      "[Iter 85300]\n",
      "[Iter 85400]\n",
      "[Iter 85500]\n",
      "[Iter 85600]\n",
      "[Iter 85700]\n",
      "[Iter 85800]\n",
      "[Iter 85846] Loss: 5.501210599682048e-10\n",
      "[Iter 85900]\n",
      "[Iter 86000]\n",
      "[Iter 86100]\n",
      "[Iter 86200]\n",
      "[Iter 86300]\n",
      "[Iter 86400]\n",
      "[Iter 86500]\n",
      "[Iter 86600]\n",
      "[Iter 86700]\n",
      "[Iter 86800]\n",
      "[Iter 86900]\n",
      "[Iter 87000]\n",
      "[Iter 87100]\n",
      "[Iter 87200]\n",
      "[Iter 87300]\n",
      "[Iter 87400]\n",
      "[Iter 87500]\n",
      "[Iter 87600]\n",
      "[Iter 87700]\n",
      "[Iter 87800]\n",
      "[Iter 87900]\n",
      "[Iter 88000]\n",
      "[Iter 88100]\n",
      "[Iter 88200]\n",
      "[Iter 88300]\n",
      "[Iter 88400]\n",
      "[Iter 88500]\n",
      "[Iter 88600]\n",
      "[Iter 88700]\n",
      "[Iter 88800]\n",
      "[Iter 88900]\n",
      "[Iter 89000]\n",
      "[Iter 89100]\n",
      "[Iter 89200]\n",
      "[Iter 89300]\n",
      "[Iter 89400]\n",
      "[Iter 89500]\n",
      "[Iter 89600]\n",
      "[Iter 89700]\n",
      "[Iter 89800]\n",
      "[Iter 89900]\n",
      "[Iter 90000]\n",
      "[Iter 90100]\n",
      "[Iter 90200]\n",
      "[Iter 90300]\n",
      "[Iter 90400]\n",
      "[Iter 90500]\n",
      "[Iter 90600]\n",
      "[Iter 90700]\n",
      "[Iter 90800]\n",
      "[Iter 90900]\n",
      "[Iter 91000]\n",
      "[Iter 91100]\n",
      "[Iter 91200]\n",
      "[Iter 91300]\n",
      "[Iter 91400]\n",
      "[Iter 91500]\n",
      "[Iter 91600]\n",
      "[Iter 91700]\n",
      "[Iter 91800]\n",
      "[Iter 91900]\n",
      "[Iter 92000]\n",
      "[Iter 92100]\n",
      "[Iter 92200]\n",
      "[Iter 92300]\n",
      "[Iter 92400]\n",
      "[Iter 92500]\n",
      "[Iter 92600]\n",
      "[Iter 92700]\n",
      "[Iter 92800]\n",
      "[Iter 92900]\n",
      "[Iter 93000]\n",
      "[Iter 93100]\n",
      "[Iter 93200]\n",
      "[Iter 93300]\n",
      "[Iter 93400]\n",
      "[Iter 93500]\n",
      "[Iter 93600]\n",
      "[Iter 93700]\n",
      "[Iter 93800]\n",
      "[Iter 93900]\n",
      "[Iter 94000]\n",
      "[Iter 94100]\n",
      "[Iter 94200]\n",
      "[Iter 94300]\n",
      "[Iter 94400]\n",
      "[Iter 94500]\n",
      "[Iter 94600]\n",
      "[Iter 94700]\n",
      "[Iter 94800]\n",
      "[Iter 94900]\n",
      "[Iter 95000]\n",
      "[Iter 95100]\n",
      "[Iter 95200]\n",
      "[Iter 95300]\n",
      "[Iter 95400]\n",
      "[Iter 95500]\n",
      "[Iter 95600]\n",
      "[Iter 95700]\n",
      "[Iter 95800]\n",
      "[Iter 95900]\n",
      "[Iter 96000]\n",
      "[Iter 96100]\n",
      "[Iter 96200]\n",
      "[Iter 96300]\n",
      "[Iter 96400]\n",
      "[Iter 96500]\n",
      "[Iter 96600]\n",
      "[Iter 96700]\n",
      "[Iter 96800]\n",
      "[Iter 96900]\n",
      "[Iter 97000]\n",
      "[Iter 97100]\n",
      "[Iter 97200]\n",
      "[Iter 97300]\n",
      "[Iter 97400]\n",
      "[Iter 97500]\n",
      "[Iter 97600]\n",
      "[Iter 97700]\n",
      "[Iter 97800]\n",
      "[Iter 97900]\n",
      "[Iter 98000]\n",
      "[Iter 98100]\n",
      "[Iter 98200]\n",
      "[Iter 98300]\n",
      "[Iter 98400]\n",
      "[Iter 98500]\n",
      "[Iter 98600]\n",
      "[Iter 98700]\n",
      "[Iter 98800]\n",
      "[Iter 98900]\n",
      "[Iter 99000]\n",
      "[Iter 99100]\n",
      "[Iter 99200]\n",
      "[Iter 99300]\n",
      "[Iter 99400]\n",
      "[Iter 99500]\n",
      "[Iter 99600]\n",
      "[Iter 99700]\n",
      "[Iter 99800]\n",
      "[Iter 99900]\n",
      "[Iter 100000]\n"
     ]
    }
   ],
   "source": [
    "(mini_kRes, mini_w1Res, mini_b1Res, mini_w2Res, mini_b2Res, miniLoss) = train(batchSize=1, iter=100000, eta=0.05, filename=\"miniLoss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image: 0\n",
      "Image: 100\n",
      "Image: 200\n",
      "Image: 300\n",
      "Image: 400\n",
      "Image: 500\n",
      "Image: 600\n",
      "Image: 700\n",
      "Image: 800\n",
      "Image: 900\n",
      "Image: 1000\n",
      "Image: 1100\n",
      "Image: 1200\n",
      "Image: 1300\n",
      "Image: 1400\n",
      "Image: 1500\n",
      "Image: 1600\n",
      "Image: 1700\n",
      "Image: 1800\n",
      "Image: 1900\n",
      "Image: 2000\n",
      "Image: 2100\n",
      "Image: 2200\n",
      "Image: 2300\n",
      "Image: 2400\n",
      "Image: 2500\n",
      "Image: 2600\n",
      "Image: 2700\n",
      "Image: 2800\n",
      "Image: 2900\n",
      "Image: 3000\n",
      "Image: 3100\n",
      "Image: 3200\n",
      "Image: 3300\n",
      "Image: 3400\n",
      "Image: 3500\n",
      "Image: 3600\n",
      "Image: 3700\n",
      "Image: 3800\n",
      "Image: 3900\n",
      "Image: 4000\n",
      "Image: 4100\n",
      "Image: 4200\n",
      "Image: 4300\n",
      "Image: 4400\n",
      "Image: 4500\n",
      "Image: 4600\n",
      "Image: 4700\n",
      "Image: 4800\n",
      "Image: 4900\n",
      "Image: 4999\n",
      "Prediction correctness: 94.56%\n"
     ]
    }
   ],
   "source": [
    "resultValid = checkValid(mini_kRes, mini_w1Res, mini_b1Res, mini_w2Res, mini_b2Res)\n",
    "print(f\"Prediction correctness: {resultValid * 100}%\")\n",
    "with open(\"./test/resultValid.txt\", \"w\") as file:\n",
    "    file.write(f\"Prediction correctness: {resultValid * 100}%\")\n",
    "# pyplot.plot(miniLoss)\n",
    "# pyplot.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image: 0\n",
      "Image: 100\n",
      "Image: 200\n",
      "Image: 300\n",
      "Image: 400\n",
      "Image: 500\n",
      "Image: 600\n",
      "Image: 700\n",
      "Image: 800\n",
      "Image: 900\n",
      "Image: 1000\n",
      "Image: 1100\n",
      "Image: 1200\n",
      "Image: 1300\n",
      "Image: 1400\n",
      "Image: 1500\n",
      "Image: 1600\n",
      "Image: 1700\n",
      "Image: 1800\n",
      "Image: 1900\n",
      "Image: 2000\n",
      "Image: 2100\n",
      "Image: 2200\n",
      "Image: 2300\n",
      "Image: 2400\n",
      "Image: 2500\n",
      "Image: 2600\n",
      "Image: 2700\n",
      "Image: 2800\n",
      "Image: 2900\n",
      "Image: 3000\n",
      "Image: 3100\n",
      "Image: 3200\n",
      "Image: 3300\n",
      "Image: 3400\n",
      "Image: 3500\n",
      "Image: 3600\n",
      "Image: 3700\n",
      "Image: 3800\n",
      "Image: 3900\n",
      "Image: 4000\n",
      "Image: 4100\n",
      "Image: 4200\n",
      "Image: 4300\n",
      "Image: 4400\n",
      "Image: 4500\n",
      "Image: 4600\n",
      "Image: 4700\n",
      "Image: 4800\n",
      "Image: 4900\n",
      "Image: 5000\n",
      "Image: 5100\n",
      "Image: 5200\n",
      "Image: 5300\n",
      "Image: 5400\n",
      "Image: 5500\n",
      "Image: 5600\n",
      "Image: 5700\n",
      "Image: 5800\n",
      "Image: 5900\n",
      "Image: 6000\n",
      "Image: 6100\n",
      "Image: 6200\n",
      "Image: 6300\n",
      "Image: 6400\n",
      "Image: 6500\n",
      "Image: 6600\n",
      "Image: 6700\n",
      "Image: 6800\n",
      "Image: 6900\n",
      "Image: 7000\n",
      "Image: 7100\n",
      "Image: 7200\n",
      "Image: 7300\n",
      "Image: 7400\n",
      "Image: 7500\n",
      "Image: 7600\n",
      "Image: 7700\n",
      "Image: 7800\n",
      "Image: 7900\n",
      "Image: 8000\n",
      "Image: 8100\n",
      "Image: 8200\n",
      "Image: 8300\n",
      "Image: 8400\n",
      "Image: 8500\n",
      "Image: 8600\n",
      "Image: 8700\n",
      "Image: 8800\n",
      "Image: 8900\n",
      "Image: 9000\n",
      "Image: 9100\n",
      "Image: 9200\n",
      "Image: 9300\n",
      "Image: 9400\n",
      "Image: 9500\n",
      "Image: 9600\n",
      "Image: 9700\n",
      "Image: 9800\n",
      "Image: 9900\n",
      "Image: 9999\n",
      "Prediction correctness: 93.5%\n"
     ]
    }
   ],
   "source": [
    "resultTest = checkTest(mini_kRes, mini_w1Res, mini_b1Res, mini_w2Res, mini_b2Res)\n",
    "print(f\"Prediction correctness: {resultTest * 100}%\")\n",
    "with open(\"./test/resultTest.txt\", \"w\") as file:\n",
    "    file.write(f\"Prediction correctness: {resultTest * 100}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f2ec3a27b206c5c715624a547105f4453c6ed312d93e4b85e955c3b1a3db3dae"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
